---
title: "Normalization of the Data"
author: "Kacper Kaszuba"
date: "`r Sys.Date()`"
output: 
    html_document:
        toc: true
        toc_float: 
            collapsed: false
---

```{r echo=FALSE, message=FALSE}
knitr::opts_chunk$set(warning=FALSE, fig.align='center')

transform_M <- function(i, df) {
    if (df[i,2] == 22) {
        return(median(df[df[,2] == 22,1]))
    } else if (df[i,2] == 23) {
        return(median(df[df[,2] == 23,1]))
    } else {
        return(median(df[df[,2] == 24,1]))
    }
}
```

# Uploading imputed data

```{r}
total <- read.csv('LFQ_imp_total.csv')
lfq_total <- total$LFQvalue # extracting the LFQ values
lfq_total.selected <- lfq_total[total$rep %in% c(22,23,24)]

mito <- read.csv('LFQ_imp_mito.csv')
lfq_mito <- mito$LFQvalue
lfq_mito.selected <- lfq_mito[mito$rep %in% c(22,23,24)]
```

**HISTOGRAM OF IMPUTED DATA**

```{r fig.align='center'}
hist(lfq_total.selected)
```

**BOXPLOT OF A IMPUTED DATA**

```{r}
boxplot(lfq_total.selected)
```

```{r}
# calculating skewness of the data
moments::skewness(lfq_total.selected)
```

The histogram tells us that the data is slightly skewed to the right. The skewness value is higher than 0, so we should transform the data according to the image below.

<center><img src="./drabinka_eng.png"/></center>

# Transformations

## Natural Log

```{r}
# Natural logarithm of the data
lfq_total.log <- log(lfq_total.selected)
```

**HISTOGRAM OF DATA TRANSFORMED BY LOGARITHM**

```{r fig.align='center'}
hist(lfq_total.log)
```

```{r}
# calculating skewness of the data
moments::skewness(lfq_total.log)
```

Now is better but we can make it closer to the normal distribution by calculating the fraction of $\frac{1}{x}$.

## Fraction

```{r}
# fraction 1/x of the data
lfq_total.frac <- 1/lfq_total.selected
```

**HISTOGRAM OF DATA TRANSFORMED BY FRACTION** $\frac{1}{x}$

```{r fig.align='center'}
hist(lfq_total.frac)
```

```{r}
# calculating skewness of the data
moments::skewness(lfq_total.frac)
```

Now we have data that is closest to a normal distribution.

## Standardization

Formula: $\tilde{y}_{ij} = \frac{y_ij - \bar{y_j}}{\theta_j}$, where:

-   $y_ij$ - value of the LFQ;
-   $\bar{y_j}$ - mean of the LFQ values;
-   $\theta_j$ - standard deviation of the LFQ values.

**HISTOGRAM OF THE STANDARDIZATIONED DATA**

```{r}
lfq_total.standard <- scale(lfq_total.frac)
hist(lfq_total.standard)
```

I performed standardization on data transformed by fraction and get data with mean equals to 0 and standard deviation equals to 1.

## Linear Regression Normalization

```{r}
# Preprocessing of the data
lfq_total.df <- as.data.frame(lfq_total.selected)
lfq_total.df$rep <- total[total$rep %in% c(22,23,24), 'rep']
lfq_total.df$med_sample <- sapply(1:nrow(lfq_total.df), function(i) transform_M(i, lfq_total.df))
colnames(lfq_total.df) <- c('lfq_value', 'rep', 'med_sample')
```

```{r message=FALSE}
library(MASS)

# Normalization
model <- rlm(lfq_value ~ med_sample, data=lfq_total.df)
lfq_total.df$norm_lfq <- model$residuals
```

**HISTOGRAM OF THE NORMALIZED DATA BY LINEAR REGRESSION**

```{r}
hist(lfq_total.df$norm_lfq)
```

## Local regression normalization

```{r message=FALSE}
library(limma)

lfq_total.reg <- normalizeCyclicLoess(cbind(lfq_total.selected, lfq_mito.selected))[,1]
```

```{r}
hist(lfq_total.reg)
```

```{r}
moments::skewness(lfq_total.reg)
```

## Variance stabilization normalization

```{r message=FALSE}
library(vsn)

# create input to the justvsn fxn
df <- total[total$rep %in% c(22,23,24), c('LFQvalue', 'Sample')]
df <- data.frame('KO_TOTALS_22'= df[df$Sample == 'KO_TOTALS_22', 'LFQvalue'],
                 'KO_TOTALS_23'= df[df$Sample == 'KO_TOTALS_23', 'LFQvalue'],
                 'KO_TOTALS_24'= df[df$Sample == 'KO_TOTALS_24', 'LFQvalue'],
                 'WT_TOTALS_22'= df[df$Sample == 'WT_TOTALS_22', 'LFQvalue'],
                 'WT_TOTALS_23'= df[df$Sample == 'WT_TOTALS_23', 'LFQvalue'],
                 'WT_TOTALS_24'= df[df$Sample == 'WT_TOTALS_24', 'LFQvalue'])

# check which row is which type
all_ko <- cbind(df[,1], df[,2], df[,3])
colnames(all_ko) <- c('KO_TOTALS_22', 'KO_TOTALS_23', 'KO_TOTALS_24')
all_wt <- cbind(df[,4], df[,5], df[,6])
colnames(all_wt) <- c('WT_TOTALS_22', 'WT_TOTALS_23', 'WT_TOTALS_24')

lfq_total.RG <- new('RGList', list(
    R = all_ko,
    G = all_wt))

lfq_total.vsn <- justvsn(lfq_total.RG)
```

After the VSN normalization we can create a histogram of our LFQ Values.

```{r}
lfq_total.vsn2 <- c(lfq_total.vsn@assayData[["R"]][,1], 
                   lfq_total.vsn@assayData[["R"]][,2], 
                   lfq_total.vsn@assayData[["R"]][,3], 
                   lfq_total.vsn@assayData[["G"]][,1],
                   lfq_total.vsn@assayData[["G"]][,2],
                   lfq_total.vsn@assayData[["G"]][,3])

hist(lfq_total.vsn2)
```

```{r include=FALSE}
# Dodatkowe rzeczy do dalszych analiz używając VSN
# We need to add more information to the VSN Object
vmd <- data.frame( # varMetadata
    labelDescription = I(c("array ID", "sample in G", "sample in R")),
    channel = c("_ALL", "G", "R"),
    row.names = c("arrayID", "sampWT", "sampKO")
)

arrayID = c('TOTALS_22', 'TOTALS_23', 'TOTALS_24')

v = data.frame(
    arrayID = arrayID,
    sampWT   = 'wild type',
    sampKO   = 'knockout')

adf = new("AnnotatedDataFrame", 
    data = v,
    varMetadata = vmd)

phenoData(lfq_total.vsn) = adf
```

## Quantile normalization

```{r message=FALSE}

# Trzeba to poprawić, bo tu się nic nie zmienia!!
library(preprocessCore)

lfq_total.quantile <- normalizeQuantiles(as.matrix(df))
hist(lfq_total.quantile)
```

```{r}
moments::skewness(lfq_total.quantile)
```

# `bestNormalize` Package for Automatic Normalization

```{r}
bestNormalize::bestNormalize(lfq_total.df$lfq_value)
```

Based on the output we should use the Ordered Quantile technique. Let's check a histogram of the transformed data by this technique.

```{r warning=FALSE}
bestNormalize::orderNorm(lfq_total.df$lfq_value) -> lfq_total.orderNorm
hist(lfq_total.orderNorm$x.t)
```

With this technique we have the perfect shape of the histogram.

# Comparison

We have biological data, so we want to do normalization which doesn't miss maintain differences between biological groups, such as control vs. treated samples.

```{r include=FALSE}
library(ggplot2)
library(ggpubr)

plotdata <- function(df, col){
    col <- rlang::sym(col)
    
    A <- ggplot(df, aes(x = celltype, y = LFQvalue, colour=celltype)) +
        geom_boxplot() +
        ggtitle('Original Data Boxplot')+
        theme(legend.position = "none")
    
    B <- ggplot(df, aes(x = celltype, y = !!col, colour=celltype)) +
        geom_boxplot() +
        ggtitle('Normalized Data Boxplot')+
        theme(legend.position = "none")
    
    ggarrange(A,B, nrow = 2)
}

df_all <- data.frame(LFQvalue = lfq_total.selected,
                     nat.log = lfq_total.log,
                     frac = lfq_total.frac,
                     standard = lfq_total.standard,
                     lrn = lfq_total.df$norm_lfq,
                     locreg = lfq_total.reg,
                     vsn = lfq_total.vsn2,
                     quan = lfq_total.quantile,
                     orderNorm = lfq_total.orderNorm$x.t,
                     celltype = as.factor(total[total$rep %in% c(22,23,24), "celltype"]))
```

```{r}
# Pomysł przedstawić wykresy boxplot na jednym
ggplot(df_all) +
    geom_boxplot(aes(y = celltype, x = nat.log)) +
    geom_boxplot(aes(y = celltype, x = frac))
```

```{r}
plotdata(df_all, "nat.log")
```

```{r}
plotdata(df_all, "frac")
```

```{r}
plotdata(df_all, "standard")
```

```{r}
plotdata(df_all, "lrn")
```

```{r}
plotdata(df_all, "locreg")
```

```{r}
plotdata(df_all, 'vsn')
```

```{r}
plotdata(df_all, 'quan')
```

```{r}
plotdata(df_all, 'orderNorm')
```

Pakiety, które można wykorzystać:

-   `MASS` - Linear regression normalization (Rlr, RlrMA, RlrMACyc)
-   `limma` - Local regression normalization (LoessF, LoessCyc), function: `normalizeCyclicLoess`
-   `vsn` - Variance stabilization normalization, function: `justvsn`
-   `preprocessCore` - Quantile normalization, function: `normalize.quantiles`
-   Median normalization - trzeba znaleźć albo napisać funkcję
-   Progenesis normalization - Progenesis data analysis software
-   EigenMS normalization: <http://sourceforge.net/projects/eigenms/>

------------------------------------------------------------------------

# References

1.  [A systematic evaluation of normalization methods in quantitative label-free proteomics](https://academic.oup.com/bib/article/19/1/1/2562889)
2.  [bestNormalize R Package](https://cran.r-project.org/web/packages/bestNormalize/vignettes/bestNormalize.html#the-ordered-quantile-technique)
