---
title: "Imputation with Machine Learning"
author: "Kacper Kaszuba"
date: "`r Sys.Date()`"
output: 
    html_document:
        toc: true
        toc_float: 
            collapsed: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, fig.align = "center", fig.keep = "all")

if (!require("missForest", quietly = TRUE))
    install.packages("missForest")
if (!require("randomForest", quietly = TRUE))
    install.packages("randomForest")
if (!require("VIM", quietly = TRUE))
    install.packages("VIM")

library(missForest)
library(ggplot2)


assign_missing <- function(protein.ids, condition, lfq_intensity) {
    # verification of the fxn assumptions
    if (!is.factor(condition)) {rlang::abort('The condition are not factor!')}

    # occurences of protein IDs per condition
    occur <- dplyr::tibble(protein.ids) |>
        dplyr::group_by(protein.ids) |>
        dplyr::summarise(len = length(protein.ids)) |>
        dplyr::distinct(len)

    # occurences of condition
    occur_per_cond <- dplyr::tibble(protein.ids, condition) |>
        dplyr::group_by(protein.ids, condition) |>
        dplyr::summarise(len = length(protein.ids))
    occur_per_cond <- unique(occur_per_cond$len)

    if (length(protein.ids)/occur != length(unique(protein.ids))) {rlang::abort('The protein IDs are not unique!')}
    if (!is.numeric(lfq_intensity)) {rlang::abort('The lfq intensities are not numeric!')}

    df <- data.frame('prot.IDs'=protein.ids, 'condition'=condition, 'lfq'=lfq_intensity)

    number_missing <- df |>
        dplyr::group_by(prot.IDs, condition) |>
        dplyr::summarise(no_NAs = sum(is.na(lfq)))

    missingness <- purrr::map(number_missing$no_NAs, function(no) {
            if (no == occur_per_cond) {
              rep('all_NA', occur_per_cond)
            } else if (no == occur_per_cond-1) {
              rep('MNAR', occur_per_cond)
            } else if (no < occur_per_cond-1 & no != 0) {
              rep('MAR', occur_per_cond)
            } else {
              rep('complete', occur_per_cond)
            }
        })
    missingness <- data.frame(do.call(c,missingness))

    prot.id.miss <- purrr::map(unique(number_missing$prot.IDs), function(id) rep(id, occur))
    prot.id.miss <- data.frame(do.call(c,prot.id.miss))

    df_miss <- data.frame(prot.id.miss, missingness)
    colnames(df_miss) <- c('prot.IDs', 'missingness')


    missingness <- lapply(unique(protein.ids), function(id) df_miss[which(df_miss$prot.IDs == id),'missingness'])
    df$missingness <- do.call(c,missingness)

    ret_list <- list(df = df, missingness=df$missingness)
}
```

I think we should use more columns to make the predicted value more specific,
more accurate. We could use:

* Sequence coverage;
* Sequence length;
* Mol weigth kDa;
* Qvalue;
* Score;
* Identyfication type (?);
* MS.MS.Count

# Package `ranger`

* Documentation: https://cran.r-project.org/web/packages/ranger/ranger.pdf

```{r data preparation}
# Data preparation to run random forest

# load raw data
protein.groups <- readr::read_tsv('./data/proteinGroups.txt',show_col_types = FALSE)

# filtering and keeping the protein IDs and gene names
protein.ids <- protein.groups |> 
    dplyr::filter(is.na(`Only identified by site`), is.na(Reverse),
                  is.na(`Potential contaminant`)) |>
    dplyr::select('Protein IDs', `Gene names`)

# extracting columns to random forest
protein.groups <- protein.groups |> 
    dplyr::filter(is.na(`Only identified by site`), is.na(Reverse),
                  is.na(`Potential contaminant`)) |>
    dplyr::select(`Number of proteins`, Peptides, `Sequence coverage [%]`, `Sequence length`, 
                  `Mol. weight [kDa]`, `Q-value`, Score, `MS/MS count`, 
                  dplyr::starts_with('LFQ Intensity') & (ends_with('22') | ends_with('23') | ends_with('24')) & dplyr::contains('TOTALS'))

# changing the colnames
colnames(protein.groups)[9:14] <- gsub('LFQ intensity ', '', colnames(protein.groups)[9:14])

# making longer data frame with one column containing all LFQ values
protein.groups <- protein.groups |>
    dplyr::mutate(prot.id = paste('prot',1:nrow(protein.groups),sep='_')) |>
    tidyr::pivot_longer(9:14, names_to = 'Sample', values_to = 'LFQvalue') |>
    tidyr::separate(col=Sample, into=c("celltype","sampletype","rep"), sep = "_", remove = FALSE) |>
    dplyr::mutate(celltype = as.factor(celltype), sampletype = as.factor(sampletype),
                  rep = as.factor(rep))

# changing values with 0 to NA
protein.groups$LFQvalue[protein.groups$LFQvalue==0] <- NA

protein.groups$missingness <- assign_missing(protein.groups$prot.id, protein.groups$celltype, protein.groups$LFQvalue)$missingness

# removing blank spaces and all separators from colnames
colnames(protein.groups)[1:8] <- c('no.proteins', 'peptides','seq.coverage','seq.len',
                                      'mol.weight.kDa','q.value','score','ms.count')

# Remove unnecessary columns and reordering columns
protein.groups.to.models <- protein.groups |>
    dplyr::select(-prot.id, -Sample) |> dplyr::select(1:11, 13, 12) |>
    dplyr::mutate(missingness = as.numeric(as.factor(missingness)),
                  celltype = as.numeric(celltype),
                  sampletype = as.numeric(sampletype),
                  rep = as.numeric(rep))

protein.groups <- protein.groups |>
    dplyr::select(-prot.id, -Sample) |> dplyr::select(1:11, 13, 12) |>
    dplyr::mutate(missingness = as.factor(missingness))
```

```{r}
# creating data with no NA to train random forest model
prot.groups.no.na <- na.omit(protein.groups.to.models)
```

## RF Model

```{r}
# set seed to avoid different models and test/train data with each run
set.seed(123)
# split data to train and test
test_data_idx <- sample(1:nrow(prot.groups.no.na), ceiling(0.3*nrow(prot.groups.no.na)))
test_data <- prot.groups.no.na[test_data_idx,]
test_data_na <- test_data |> dplyr::mutate(LFQvalue = NA)
train_data <- prot.groups.no.na[-test_data_idx,]
```

```{r}
# training default random forest model
n_features <- ncol(train_data[,-13])

ames_rf1 <- ranger::ranger(
  LFQvalue ~ ., 
  data = train_data,
  mtry = floor(n_features / 3),
  respect.unordered.factors = "order",
  seed = 123
)

# get OOB RMSE
(default_rmse <- sqrt(ames_rf1$prediction.error))
```

## Model Tunning

```{r echo=FALSE}
# # hyperparameter grid
# hyper_grid_rf <- expand.grid(
#     num.trees = c(100,300,500),
#     mtry = floor(n_features * c(.05, .15, .25, .333, .4)),
#     min.node.size = c(1, 3, 5, 10), 
#     replace = c(TRUE, FALSE),                               
#     sample.fraction = c(.5, .63, .8),                       
#     rmse = NA 
# )
# 
# # execute full cartesian grid search
# for(i in seq_len(nrow(hyper_grid_rf))) {
#   # fit model for ith hyperparameter combination
#   fit <- ranger::ranger(
#     formula         = LFQvalue ~ ., 
#     data            = train_data, 
#     num.trees       = hyper_grid_rf$num.trees[i],
#     mtry            = hyper_grid_rf$mtry[i],
#     min.node.size   = hyper_grid_rf$min.node.size[i],
#     replace         = hyper_grid_rf$replace[i],
#     sample.fraction = hyper_grid_rf$sample.fraction[i],
#     verbose         = FALSE,
#     seed            = 123,
#     respect.unordered.factors = 'order',
#   )
#   # export OOB error 
#   hyper_grid_rf$rmse[i] <- sqrt(fit$prediction.error)
# }
```

```{r echo=FALSE}
# # assess top 10 models
# DT::datatable(
#     hyper_grid_rf |>
#       dplyr::arrange(rmse) |>
#       dplyr::mutate(perc_gain = (default_rmse - rmse) / default_rmse * 100) |>
#       head(10),
#     options=list(searching=FALSE, paging=FALSE, info=FALSE)
# )
```

<style>
    table {
      width: 100%;
      border-collapse: collapse;
    }
    th, td {
      width: 14.28%; /* Distribute width equally (100% / 7 columns) */
      border: 1px #f2f2f2;
      text-align: center; /* Center the text */
      padding: 8px;
    }
    th {
      background-color: #f2f2f2;
      border: 0px;
    }
</style>

<table>
  <thead>
    <tr>
      <th></th>
      <th>num.trees</th>
      <th>mtry</th>
      <th>min.node.size</th>
      <th>replace</th>
      <th>sample.fraction</th>
      <th>rmse</th>
      <th>perc_gain</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>100</td>
      <td>4</td>
      <td>5</td>
      <td>false</td>
      <td>0.8</td>
      <td>36184321.6466</td>
      <td>2.8631</td>
    </tr>
    <tr>
      <td>2</td>
      <td>500</td>
      <td>4</td>
      <td>5</td>
      <td>false</td>
      <td>0.8</td>
      <td>367032968.8757</td>
      <td>1.47133</td>
    </tr>
    <tr>
      <td>3</td>
      <td>300</td>
      <td>4</td>
      <td>5</td>
      <td>false</td>
      <td>0.8</td>
      <td>367963900.30284</td>
      <td>1.2214</td>
    </tr>
    <tr>
      <td>4</td>
      <td>500</td>
      <td>4</td>
      <td>1</td>
      <td>true</td>
      <td>0.8</td>
      <td>370084110.1524</td>
      <td>0.6523</td>
    </tr>
    <tr>
      <td>5</td>
      <td>500</td>
      <td>4</td>
      <td>10</td>
      <td>false</td>
      <td>0.8</td>
      <td>370380581.2619</td>
      <td>0.5727</td>
    </tr>
    <tr>
      <td>6</td>
      <td>300</td>
      <td>4</td>
      <td>1</td>
      <td>true</td>
      <td>0.63</td>
      <td>371446664.9562</td>
      <td>0.2865</td>
    </tr>
    <tr>
      <td>7</td>
      <td>100</td>
      <td>4</td>
      <td>5</td>
      <td>false</td>
      <td>0.8</td>
      <td>372131148.9947</td>
      <td>0.1027</td>
    </tr>
    <tr>
      <td>8</td>
      <td>300</td>
      <td>4</td>
      <td>10</td>
      <td>false</td>
      <td>0.8</td>
      <td>372169999.3198</td>
      <td>0.0923</td>
    </tr>
    <tr>
      <td>9</td>
      <td>300</td>
      <td>4</td>
      <td>4</td>
      <td>true</td>
      <td>0.63</td>
      <td>372767670.8139</td>
      <td>-0.0681</td>
    </tr>
    <tr>
      <td>10</td>
      <td>300</td>
      <td>4</td>
      <td>3</td>
      <td>true</td>
      <td>0.8</td>
      <td>373586116.5828</td>
      <td>-0.2878</td>
    </tr>
  </tbody>
</table>


Base on the output of the grid search, we can see that there is better model than default and 
it is random forest model with the following hyperparameters:

* num.trees = 100
* mtry = 4
* min.node.size = 5
* replace = FALSE
* sample.fraction = 0.80

```{r random forest}
# running random forest model
# rforest <- randomForest::randomForest(LFQvalue ~ ., data=train_data,)
rforest <- ranger::ranger(LFQvalue ~ .,
                          data=train_data,
                          num.trees = 100,
                          mtry = 4,
                          min.node.size = 5,
                          replace = FALSE,
                          sample.fraction = 0.8,
                          seed = 123,
                          importance = 'impurity')
```

```{r}
# Fitted model
rforest
```

```{r varImpPlot}
# produce variable importance plot
f1 <- vip::vip(rforest, num_features=12)
gridExtra::grid.arrange(f1)
```

```{r}
# predict the values for missing data
pred_test_na <- predict(object = rforest, data = test_data_na)
test_data_imp <- test_data_na |> dplyr::mutate(LFQvalue = pred_test_na$predictions)
```

## Model Evaluation

```{r}
# Model Evaluation
y_pred <- test_data_imp$LFQvalue
y_true <- test_data$LFQvalue

# NRMSE
nrmse <- round(missForest::nrmse(ximp = test_data_imp, xmis = test_data_na, xtrue = test_data),4)

# MSE
mse <- round(mean((log2(y_pred) - log2(y_true))^2),4)

# RMSE
rmse <- round(sqrt(mse),4)

# MAE
mae <- round(mean(abs(log2(y_pred) - log2(y_true))),4)

# R-Squared
r2 <- round(summary(lm(y_true ~ y_pred))$r.squared,4)
```

```{r echo=FALSE}
rf_measures <- data.frame(NRMSE=nrmse, MSE=mse, RMSE=rmse, MAE=mae, R2=r2, row.names = 'RF')

DT::datatable(rf_measures, options=list(searching=FALSE, paging=FALSE, info=FALSE))
```

## Predict Orginal Data

```{r predict rf}
# extracting missing rows - can be usefull later
missing <- which(is.na(protein.groups$LFQvalue))

# predict the values for NA rows
predictions <- predict(rforest, protein.groups.to.models[missing,])

# data frame with predicted LFQ values by random forest model
imputed_RF <- protein.groups
imputed_RF[missing,13] <- predictions$predictions
```

## Results

```{r echo=FALSE}
# extracting rows for KO and WT type
imputed_RF_KO_TOTALS <- imputed_RF[which(imputed_RF$celltype == 'KO' & imputed_RF$sampletype == 'TOTALS'),]
imputed_RF_WT_TOTALS <- imputed_RF[which(imputed_RF$celltype == 'WT' & imputed_RF$sampletype == 'TOTALS'),]

# plotting histograms of extracted rows
hist_RF <- ggpubr::annotate_figure(
    ggpubr::ggarrange(
        ggplot(data = imputed_RF_KO_TOTALS, aes(x=log2(LFQvalue), fill=rep))+
            geom_histogram(position='identity', alpha=0.5, bins=20)+labs(fill='KO'),
        ggplot(data = imputed_RF_WT_TOTALS, aes(x=log2(LFQvalue), fill=rep))+
            geom_histogram(position='identity', alpha=0.5, bins=20)+labs(fill='WT'),
        nrow=2,ncol=1
    ),
    top = 'Histograms of Imputed Data with Random Forest - more features'
)

hist_RF
```

```{r}
# calculating skewness for imputed data
rbind(imputed_RF_KO_TOTALS, imputed_RF_WT_TOTALS) |>
    dplyr::group_by(celltype, rep) |>
    dplyr::summarise(skewness = moments::skewness(log2(LFQvalue)))
```

```{r}
# preparing data to calculate CV (Corelation of Variation)
imputed_RF_KO_wide <- imputed_RF_KO_TOTALS |>
    dplyr::select(celltype, rep, LFQvalue) |>
    dplyr::mutate(batch = paste(celltype,rep,sep = '_')) |>
    dplyr::select(batch, LFQvalue) |>
    tidyr::pivot_wider(dplyr::everything(), names_from = batch, values_from = LFQvalue) |>
    tidyr::unnest()

imputed_RF_WT_wide <- imputed_RF_WT_TOTALS |>
    dplyr::select(celltype, rep, LFQvalue) |>
    dplyr::mutate(batch = paste(celltype,rep,sep = '_')) |>
    dplyr::select(batch, LFQvalue) |>
    tidyr::pivot_wider(dplyr::everything(), names_from = batch, values_from = LFQvalue) |>
    tidyr::unnest()
```

```{r}
# calculating the CV [%]
cv <- function(x) sd(x) / mean(x) * 100

cv_RF_KO <- apply(imputed_RF_KO_wide, 1, cv)
cv_RF_WT <- apply(imputed_RF_WT_wide, 1, cv)

# data frame containing calculated CV
cv_all_RF <- data.frame(RF_KO = cv_RF_KO, RF_WT = cv_RF_WT) |>
    tidyr::pivot_longer(dplyr::everything(), names_to = 'Sample', values_to = 'CV')

# plotting the CV results
cv_RF_plot <-ggplot(data = cv_all_RF, aes(x=Sample, y=CV, fill=Sample))+
    geom_boxplot(width=0.3)+
    geom_violin(alpha=0.4)+
    labs(title='Violin Plots for CV [%] - RF Imputation', x=NULL, y='CV [%]')+
    theme(legend.position = 'none')
cv_RF_plot
```

```{r}
# basic stats of CV for RF
cv_RF_stats <- DT::datatable(
    cv_all_RF |>
        dplyr::group_by(Sample) |>
        dplyr::summarise(mean=mean(CV),median=median(CV),sd=sd(CV)),
    rownames = FALSE, options = list(searching=FALSE, paging=FALSE, info=FALSE)
)
cv_RF_stats
```

```{r}
# plotting the result of RF imputation 
violin_RF_by_group <- ggpubr::ggarrange(
    ggplot(data = imputed_RF_KO_TOTALS, aes(x=rep, y=log2(LFQvalue), fill=rep))+
        geom_boxplot(width=0.3)+
        geom_violin(alpha=0.4)+
        labs(title='KO TOTALS - RF Imputation', x=NULL)+theme(legend.position = 'none'),
    ggplot(data = imputed_RF_WT_TOTALS, aes(x=rep, y=log2(LFQvalue), fill=rep))+
        geom_boxplot(width=0.3)+
        geom_violin(alpha=0.4)+
        labs(title='WT TOTALS - RF Imputation', x=NULL)+theme(legend.position = 'none'),
    nrow=2,ncol=1
)

violin_RF_by_group
```

# Package `caret` - KNN

## kNN Model


```{r kNN}
# calculating kNN model
model_kNN <- caret::train(LFQvalue ~ ., data=train_data, method='knn')

model_kNN
```

```{r}
plot(model_kNN)
```

```{r}
# predict the values for missing data
kNN_pred_test_na <- predict(model_kNN, test_data_na[,1:12])
kNN_test_data_imp <- test_data_na |> dplyr::mutate(LFQvalue = kNN_pred_test_na)
```

## Model Evaluation

```{r}
# Model Evaluation
y_pred_kNN <- kNN_test_data_imp$LFQvalue
y_true_kNN <- test_data$LFQvalue

# NRMSE
nrmse_kNN <- round(missForest::nrmse(ximp = kNN_test_data_imp, xmis = test_data_na, xtrue = test_data),4)

# MSE
mse_kNN <- round(mean((log2(y_pred_kNN) - log2(y_true_kNN))^2),4)

# RMSE
rmse_kNN <- round(sqrt(mse_kNN),4)

# MAE
mae_kNN <- round(mean(abs(log2(y_pred_kNN) - log2(y_true_kNN))),4)

# R-Squared
r2_kNN <- round(summary(lm(y_true_kNN ~ y_pred_kNN))$r.squared,4)
```

```{r echo=FALSE}
kNN_measures <- data.frame(NRMSE=nrmse_kNN, MSE=mse_kNN, RMSE=rmse_kNN, MAE=mae_kNN, R2=r2_kNN, row.names = 'kNN')

DT::datatable(kNN_measures, options=list(searching=FALSE, paging=FALSE, info=FALSE))
```

## Predict Original Data

```{r predict kNN}
# predict the values for NA rows
predictions2 <- predict(model_kNN, protein.groups.to.models[missing,1:12])

# data frame with predicted LFQ values by random forest model
imputed_kNN <- protein.groups
imputed_kNN[missing,13] <- predictions2
```

## Results

```{r}
# extracting rows for KO and WT type
imputed_kNN_KO_TOTALS <- imputed_kNN[which(imputed_kNN$celltype == 'KO' & imputed_kNN$sampletype == 'TOTALS'),]
imputed_kNN_WT_TOTALS <- imputed_kNN[which(imputed_kNN$celltype == 'WT' & imputed_kNN$sampletype == 'TOTALS'),]

# ploting distribution of extracted rows
hist_kNN <- ggpubr::annotate_figure(
    ggpubr::ggarrange(
        ggplot(data = imputed_kNN_KO_TOTALS, aes(x=log2(LFQvalue), fill=rep))+
            geom_histogram(position='identity', alpha=0.5, bins=20)+labs(fill='KO'),
        ggplot(data = imputed_kNN_WT_TOTALS, aes(x=log2(LFQvalue), fill=rep))+
            geom_histogram(position='identity', alpha=0.5, bins=20)+labs(fill='WT'),
        nrow=2,ncol=1
    ),
    top = 'Histograms of Imputed Data with kNN - more features'
)
hist_kNN
```

```{r}
# calculating skewnnes of imputed data with kNN
rbind(imputed_kNN_KO_TOTALS, imputed_kNN_WT_TOTALS) |>
    dplyr::group_by(celltype, rep) |>
    dplyr::summarise(skewness = moments::skewness(log2(LFQvalue)))
```

```{r}
# preparing data to calculate CV (Corelation of Variation)
imputed_kNN_KO_wide <- imputed_kNN_KO_TOTALS |>
    dplyr::select(celltype, rep, LFQvalue) |>
    dplyr::mutate(batch = paste(celltype,rep,sep = '_')) |>
    dplyr::select(batch, LFQvalue) |>
    tidyr::pivot_wider(dplyr::everything(), names_from = batch, values_from = LFQvalue) |>
    tidyr::unnest()

imputed_kNN_WT_wide <- imputed_kNN_WT_TOTALS |>
    dplyr::select(celltype, rep, LFQvalue) |>
    dplyr::mutate(batch = paste(celltype,rep,sep = '_')) |>
    dplyr::select(batch, LFQvalue) |>
    tidyr::pivot_wider(dplyr::everything(), names_from = batch, values_from = LFQvalue) |>
    tidyr::unnest()
```

```{r echo=FALSE}
# calculating the CV [%]
cv <- function(x) sd(x) / mean(x) * 100

cv_kNN_KO <- apply(imputed_kNN_KO_wide, 1, cv)
cv_kNN_WT <- apply(imputed_kNN_WT_wide, 1, cv)

# data frame with calculated CV
cv_all <- data.frame(kNN_KO = cv_kNN_KO, kNN_WT = cv_kNN_WT) |>
    tidyr::pivot_longer(dplyr::everything(), names_to = 'Sample', values_to = 'CV')

# ploting the calculated CV
cv_kNN_plot <- ggplot(data = cv_all, aes(x=Sample, y=CV, fill=Sample))+
    geom_boxplot(width=0.3)+
    geom_violin(alpha=0.4)+
    labs(title='Violin Plots for CV [%] - kNN Imputation', x=NULL, y='CV [%]')+
    theme(legend.position = 'none')
cv_kNN_plot
```

```{r}
# basic stats
cv_kNN_stats <- DT::datatable(
    cv_all |>
        dplyr::group_by(Sample) |>
        dplyr::summarise(mean=mean(CV),median=median(CV),sd=sd(CV)),
    rownames = FALSE, options = list(searching=FALSE, paging=FALSE, info=FALSE)
)
cv_kNN_stats
```

```{r}
# plotting the result of kNN imputation 
violin_kNN_by_group <- ggpubr::ggarrange(
    ggplot(data = imputed_kNN_KO_TOTALS, aes(x=rep, y=log2(LFQvalue), fill=rep))+
        geom_boxplot(width=0.3)+
        geom_violin(alpha=0.4)+
        labs(title='KO TOTALS - kNN Imputation', x=NULL)+theme(legend.position = 'none'),
    ggplot(data = imputed_kNN_WT_TOTALS, aes(x=rep, y=log2(LFQvalue), fill=rep))+
        geom_boxplot(width=0.3)+
        geom_violin(alpha=0.4)+
        labs(title='WT TOTALS - kNN Imputation', x=NULL)+theme(legend.position = 'none'),
    nrow=2,ncol=1
)
violin_kNN_by_group
```

# Linear Regression

## LM Model

```{r}
# train model - stepwise selection
lm_model <- lm(LFQvalue ~ ., data=train_data)
summary(lm_model)
```

After stepwise selection the final model has formula:

$$LFQvalue = 8631815 \cdot no.proteins -18172773 \cdot peptides + 1794237 \cdot
seq.coverage +\\ + 807933 \cdot mol.weight.kDa + 430143 \cdot score + 1490175 \cdot ms.count$$

```{r}
lm_model <- lm(LFQvalue ~ 0 + no.proteins + peptides + seq.coverage + mol.weight.kDa + score + ms.count,
               data=train_data)
summary(lm_model)
```

```{r}
# Correlation plot
corrplot::corrplot(cor(train_data), method = "color", addCoef.col = "black", number.cex = 0.7)
```

```{r}
# predict the values for missing data
lm_pred_test_na <- predict(lm_model, test_data_na)
lm_test_data_imp <- test_data_na |> dplyr::mutate(LFQvalue = abs(lm_pred_test_na))
```

## Model Evaluation

```{r}
# Model Evaluation
y_pred_lm <- lm_test_data_imp$LFQvalue
y_true_lm <- test_data$LFQvalue

# NRMSE
nrmse_lm <- round(missForest::nrmse(ximp = lm_test_data_imp, xmis = test_data_na, xtrue = test_data),4)

# MSE
mse_lm <- round(mean((log2(y_pred_lm) - log2(y_true_lm))^2),4)

# RMSE
rmse_lm <- round(sqrt(mse_lm),4)

# MAE
mae_lm <- round(mean(abs(log2(y_pred_lm) - log2(y_true_lm))),4)

# R-Squared
r2_lm <- round(summary(lm(y_true_lm ~ y_pred_lm))$r.squared,4)
```

```{r echo=FALSE}
lm_measures <- data.frame(NRMSE=nrmse_lm, MSE=mse_lm, RMSE=rmse_lm, MAE=mae_lm, R2=r2_lm, row.names = 'LM')

DT::datatable(lm_measures, options=list(searching=FALSE, paging=FALSE, info=FALSE))
```

# Package `pcaMethods` - PCA

* Documentation: https://www.bioconductor.org/packages/release/bioc/manuals/pcaMethods/man/pcaMethods.pdf

## PCA Model

```{r}
# train pca model
pca_model <- pcaMethods::pca(train_data)
pca_model
```

```{r}
# predict the values for missing data
pca_pred_test_na <- predict(pca_model, test_data_na)
pca_test_data_imp <- test_data_na |> dplyr::mutate(LFQvalue = pca_pred_test_na$x[,"LFQvalue"])
```

## Model Evaluation

```{r}
# Model Evaluation
y_pred_pca <- pca_test_data_imp$LFQvalue
y_true_pca <- test_data$LFQvalue

# NRMSE
nrmse_pca <- round(missForest::nrmse(ximp = pca_test_data_imp, xmis = test_data_na, xtrue = test_data),4)

# MSE
mse_pca <- round(mean((log2(y_pred_pca) - log2(y_true_pca))^2),4)

# RMSE
rmse_pca <- round(sqrt(mse_pca),4)

# MAE
mae_pca <- round(mean(abs(log2(y_pred_pca) - log2(y_true_pca))),4)

# R-Squared
r2_pca <- round(summary(lm(y_true_pca ~ y_pred_pca))$r.squared,4)
```

```{r echo=FALSE}
pca_measures <- data.frame(NRMSE=nrmse_pca, MSE=mse_pca, RMSE=rmse_pca, MAE=mae_pca, R2=r2_pca, row.names = 'PCA')

DT::datatable(pca_measures, options=list(searching=FALSE, paging=FALSE, info=FALSE))
```

# Comparison of Models

---

<center><b style='font-size:26px'>MODELS</b></center>

---

```{r echo=FALSE}
measures <- rbind(rf_measures, kNN_measures, lm_measures, pca_measures)

# Find the minimum values in the first four columns
min_val <- apply(measures[, 1:4], 2, min, na.rm = TRUE)

# Find the maximum value in the 5th column
max_val <- max(measures[, 5], na.rm = TRUE)

# Create the datatable and apply conditional formatting
DT::datatable(measures, 
          options = list(searching = FALSE, paging = FALSE, info = FALSE)) |>
  DT::formatStyle(columns = 1:4, backgroundColor = DT::styleEqual(min_val, 'lightgreen')) |>
  DT::formatStyle(columns = 5, backgroundColor = DT::styleEqual(max_val, 'lightgreen'))
```

---

<center><b style='font-size:26px'>HISTOGRAMS</b></center>

---

```{r comp hist, echo=FALSE}
hist_RF
hist_kNN
```

---

<center><b style='font-size:26px'>VIOLIN + BOX</b></center>

---

```{r comp violin+box, echo=FALSE}
violin_RF_by_group
violin_kNN_by_group
```

---

<center><b style='font-size:26px'>CORELATION OF VARIATION</b></center>

---

```{r comp cv, echo=FALSE}
ggpubr::ggarrange(cv_RF_plot,cv_kNN_plot+ylab(NULL), nrow=1,ncol=2)
```

---

<center><b style='font-size:26px'>CV BASIC STATS</b></center>

---

```{r echo=FALSE}
cv_RF_stats
cv_kNN_stats
```

# p-value

```{r echo=FALSE}
mitocarta <- read.csv("./data/Human.MitoCarta3.0.csv")

ttest <- function(df, grp1, grp2){ 
  x = df[grp1]
  y = df[grp2]
  x = as.numeric((x))
  y = as.numeric((y))
  results = t.test(x,y, 
                   alternative = 'two.sided', #one-sided: 'greater' is x > y
                   paired = T,
                   na.action=na.omit) 
  results$p.value
}

p.cutoff = 0.05 #set p value cutoff
FC.cutoff = 1 # set fold change cutoff
```

```{r echo=FALSE}
protein.groups[is.na(protein.groups$LFQvalue), "LFQvalue"] <- 0

nonimputed_df <- protein.groups |>
    dplyr::select(celltype, sampletype, rep, LFQvalue) |>
    dplyr::mutate(sample = paste(celltype,sampletype,rep, sep='_')) |>
    dplyr::select(sample,LFQvalue) |>
    tidyr::pivot_wider(dplyr::everything(), names_from = sample, values_from = LFQvalue) |>
    tidyr::unnest() |>
    dplyr::mutate(`Protein IDs` = protein.ids$`Protein IDs`) |>
    dplyr::select(`Protein IDs`, dplyr::contains('TOTALS'))
```

```{r echo=FALSE}
pvalue_nonimp <- nonimputed_df |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(nonimputed_df, 1, ttest, 
                  grp1=grep("KO_TOTALS_2", colnames(nonimputed_df)), 
                  grp2=grep("WT_TOTALS_2", colnames(nonimputed_df)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))
```

```{r echo=FALSE}
hist_p_nonimp <-ggplot(data = pvalue_nonimp, aes(x = p_OCIAD1_TOTALS, fill=significant)) + geom_histogram(bins = 100)
```

```{r}
mean_p_nonimp <- mean(pvalue_nonimp$p_OCIAD1_TOTALS, na.rm=TRUE)
```

```{r echo=FALSE}
# Add protein IDs
imputed_df_RF <- cbind.data.frame(imputed_RF, protein.ids) |>
    dplyr::select(`Protein IDs`, `Gene names`, celltype, sampletype, rep, LFQvalue) |>
    dplyr::mutate(Imputed = ifelse(seq_along(LFQvalue) %in% missing, TRUE, FALSE),
                  sample= paste(sampletype, celltype, sep='_'),
                  group = paste(celltype,sampletype,rep, sep='_'))

imputed_df_RF$LFQvalue <- log2(imputed_df_RF$LFQvalue)
```

```{r echo=FALSE}
imputed_df_RF_wide <- imputed_df_RF |>
    dplyr::select(group, `Protein IDs`, LFQvalue) |>
    tidyr::pivot_wider(names_from = group, values_from = LFQvalue)

# means <- imputed_df_RF %>%
#   dplyr::select(sample, `Protein IDs`, LFQvalue) %>%
#   dplyr::group_by(sample, `Protein IDs`) %>% 
#   dplyr::summarise(mean=mean(LFQvalue))
# 
# means <- tidyr::pivot_wider(means, names_from = sample, values_from = mean) |>
#     dplyr::mutate(FC_TOTALS = TOTALS_KO - TOTALS_WT)
# 
# FC <- merge(means, imputed_df_RF_wide)
# FC <- FC |> dplyr::mutate(gene.names = proteingroups$`Gene names`)
# FC <- merge(FC, mitocarta, by.x = 'gene.names', by.y = 'Symbol')
```

```{r echo=FALSE}
pvalue_RF <- imputed_df_RF_wide |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(imputed_df_RF_wide, 1, ttest, 
                  grp1=grep("KO_TOTALS_2", colnames(imputed_df_RF_wide)), 
                  grp2=grep("WT_TOTALS_2", colnames(imputed_df_RF_wide)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))
```

```{r echo=FALSE}
hist_p_RF <- ggplot(data = pvalue_RF, aes(x = p_OCIAD1_TOTALS, fill=significant)) + geom_histogram(bins = 100)
```

```{r echo=FALSE}
mean_p_RF <- mean(pvalue_RF$p_OCIAD1_TOTALS)
```

```{r}
# Add protein IDs
imputed_df_kNN <- cbind.data.frame(imputed_kNN, protein.ids) |>
    dplyr::select(`Protein IDs`, `Gene names`, celltype, sampletype, rep, LFQvalue) |>
    dplyr::mutate(Imputed = ifelse(seq_along(LFQvalue) %in% missing, TRUE, FALSE),
                  sample= paste(sampletype, celltype, sep='_'),
                  group = paste(celltype,sampletype,rep, sep='_'))

imputed_df_kNN$LFQvalue <- log2(imputed_df_kNN$LFQvalue)
```

```{r}
imputed_df_kNN_wide <- imputed_df_kNN |>
    dplyr::select(group, `Protein IDs`, LFQvalue) |>
    tidyr::pivot_wider(names_from = group, values_from = LFQvalue)

# means <- imputed_df_kNN %>%
#   dplyr::select(sample, `Protein IDs`, LFQvalue) %>%
#   dplyr::group_by(sample, `Protein IDs`) %>% 
#   dplyr::summarise(mean=mean(LFQvalue))
# 
# means <- tidyr::pivot_wider(means, names_from = sample, values_from = mean) |>
#     dplyr::mutate(FC_TOTALS = TOTALS_KO - TOTALS_WT)
# 
# FC <- merge(means, imputed_df_kNN_wide)
# FC <- FC |> dplyr::mutate(gene.names = proteingroups$`Gene names`)
# FC <- merge(FC, mitocarta, by.x = 'gene.names', by.y = 'Symbol')
```

```{r}
pvalue_kNN <- imputed_df_kNN_wide |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(imputed_df_kNN_wide, 1, ttest, 
                  grp1=grep("KO_TOTALS_2", colnames(imputed_df_kNN_wide)), 
                  grp2=grep("WT_TOTALS_2", colnames(imputed_df_kNN_wide)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))
```

```{r}
hist_p_kNN <- ggplot(data = pvalue_kNN, aes(x = p_OCIAD1_TOTALS, fill=significant)) + geom_histogram(bins = 100)
```

```{r}
mean_p_kNN <- mean(pvalue_kNN$p_OCIAD1_TOTALS)
```

```{r echo=FALSE}
# Compare all together
ggpubr::ggarrange(hist_p_nonimp+ 
                      labs(title = 't-test p-value of non-imputed data', x=NULL), 
                  hist_p_RF + 
                      labs(title = 't-test p-value of imputed data with Random Forest', x=NULL) +
                      theme(legend.position = 'none'), 
                  hist_p_kNN + 
                      labs(title = 't-test p-value of imputed data with kNN') +
                      theme(legend.position = 'none'), 
                  nrow=3, ncol=1)
```

---

<center><b style='font-size:26px'>MEAN OF t-test p-value</b></center>

---

```{r echo=FALSE}
# means of p-value comparison
means <- data.frame(`Non-Imputed` = mean_p_nonimp, RF = mean_p_RF, kNN = mean_p_kNN, row.names='mean')

DT::datatable(means, options=list(searching=FALSE, paging=FALSE, info=FALSE))
```

