---
title: "Comparison"
author: "Kacper Kaszuba"
date: "`r Sys.Date()`"
output: 
    html_document:
        toc: true
        toc_float: 
            collapsed: false
---

<style>
    table {
      width: 100%;
      border-collapse: collapse;
    }
    th, td {
      width: 14.28%; /* Distribute width equally (100% / 7 columns) */
      border: 1px #f2f2f2;
      text-align: center; /* Center the text */
      padding: 8px;
    }
    th {
      background-color: #f2f2f2;
      border: 0px;
    }
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, fig.align = "center", fig.keep = "all", echo=FALSE)

if (!require("randomForest", quietly = TRUE))
    install.packages("randomForest")
if (!require("caret", quietly = TRUE))
    install.packages("caret")
if (!require('pcaMethods', quietly = TRUE))
    install.packages('pcaMethods')
if (!require('DT', quietly = TRUE))
    install.packages('DT')

show_cv_table <- function(df) {
    DT::datatable(df, rownames = FALSE, 
              options=list(searching=FALSE, paging=FALSE, info=FALSE)) %>%
    DT::formatStyle(columns = 'mean_KO', 
                    background = DT::styleInterval(c(-20, 20), c('white','lightgreen', 'white'))) %>%
    DT::formatStyle(columns = 'mean_WT', 
                    background = DT::styleInterval(c(-20,20), c('white','lightgreen', 'white'))) %>%
    DT::formatStyle(columns = 'median_KO', 
                    background = DT::styleInterval(c(-20,20), c('white','lightgreen', 'white'))) %>%
    DT::formatStyle(columns = 'median_WT', 
                    background = DT::styleInterval(c(-20, 20), c('white','lightgreen', 'white')))
}

assign_missing <- function(protein.ids, condition, lfq_intensity) {
    # verification of the fxn assumptions
    if (!is.factor(condition)) {rlang::abort('The condition are not factor!')}

    # occurences of protein IDs per condition
    occur <- dplyr::tibble(protein.ids) |>
        dplyr::group_by(protein.ids) |>
        dplyr::summarise(len = length(protein.ids)) |>
        dplyr::distinct(len)

    # occurences of condition
    occur_per_cond <- dplyr::tibble(protein.ids, condition) |>
        dplyr::group_by(protein.ids, condition) |>
        dplyr::summarise(len = length(protein.ids))
    occur_per_cond <- unique(occur_per_cond$len)

    if (length(protein.ids)/occur != length(unique(protein.ids))) {rlang::abort('The protein IDs are not unique!')}
    if (!is.numeric(lfq_intensity)) {rlang::abort('The lfq intensities are not numeric!')}

    df <- data.frame('prot.IDs'=protein.ids, 'condition'=condition, 'lfq'=lfq_intensity)

    number_missing <- df |>
        dplyr::group_by(prot.IDs, condition) |>
        dplyr::summarise(no_NAs = sum(is.na(lfq)))

    missingness <- purrr::map(number_missing$no_NAs, function(no) {
            if (no == occur_per_cond) {
              rep('all_NA', occur_per_cond)
            } else if (no == occur_per_cond-1) {
              rep('MNAR', occur_per_cond)
            } else if (no < occur_per_cond-1 & no != 0) {
              rep('MAR', occur_per_cond)
            } else {
              rep('complete', occur_per_cond)
            }
        })
    missingness <- data.frame(do.call(c,missingness))

    prot.id.miss <- purrr::map(unique(number_missing$prot.IDs), function(id) rep(id, occur))
    prot.id.miss <- data.frame(do.call(c,prot.id.miss))

    df_miss <- data.frame(prot.id.miss, missingness)
    colnames(df_miss) <- c('prot.IDs', 'missingness')


    missingness <- lapply(unique(protein.ids), function(id) df_miss[which(df_miss$prot.IDs == id),'missingness'])
    df$missingness <- do.call(c,missingness)

    ret_list <- list(df = df, missingness=df$missingness)
}

ttest <- function(df, grp1, grp2){ 
  x = df[grp1]
  y = df[grp2]
  x = as.numeric((x))
  y = as.numeric((y))
  results = t.test(x,y, 
                   alternative = 'two.sided', #one-sided: 'greater' is x > y
                   paired = T,
                   na.action=na.omit)
  results$p.value
}

p.cutoff = 0.05 #set p value cutoff
FC.cutoff = 1 # set fold change cutoff

transform_M <- function(i, df) {
    if (df[i,2] == 22) {
        return(median(df[df[,2] == 22,1]))
    } else if (df[i,2] == 23) {
        return(median(df[df[,2] == 23,1]))
    } else {
        return(median(df[df[,2] == 24,1]))
    }
}

plothist <- function(df, title='', plot.title.and.legend=TRUE) {
    if (!is.data.frame(df)) { df <- as.data.frame(df)}
    
    # Assuming LFQ_KO is our data frame with at least 3 columns
    # Reshape the data to a long format
    df <- df %>%
        pivot_longer(cols = 1:ncol(df), names_to = "Rep", values_to = "LFQValue")
    
    # Plot all histograms on the same plot using ggplot
    if (plot.title.and.legend) {
        ret_plot <- ggplot(df, aes(x = LFQValue, fill = Rep)) +
            geom_histogram(alpha = 0.4, position = "identity", bins = 30) +
            labs(title = paste(title), x = "Values", y = "Frequency") +
            theme(legend.title = element_blank())
    } else {
        ret_plot <- ggplot(df, aes(x = LFQValue, fill = Rep)) +
            geom_histogram(alpha = 0.4, position = "identity", bins = 30) +
            labs(x = "Values", y = "Frequency") +
            theme(legend.title = element_blank(), legend.position = 'none')
    }
    return(ret_plot)
}

ordernorm <- function(df) {
    LFQ.22 <- bestNormalize::orderNorm(df[,1])$x.t
    LFQ.23 <- bestNormalize::orderNorm(df[,2])$x.t
    LFQ.24 <- bestNormalize::orderNorm(df[,3])$x.t
    
    if (startsWith(x = colnames(df)[1], 'KO')) {
        return(data.frame(KO_TOTALS_22 = LFQ.22,
                          KO_TOTALS_23 = LFQ.23,
                          KO_TOTALS_24 = LFQ.24))
    } else {
        return(data.frame(WT_TOTALS_22 = LFQ.22,
                          WT_TOTALS_23 = LFQ.23,
                          WT_TOTALS_24 = LFQ.24))
    }
}

plotviolin <- function(df, xlab='', ylab='LFQValue') {
    if (!is.data.frame(df)) { df <- as.data.frame(df)}
    
    df <- df %>%
        pivot_longer(1:ncol(df),names_to = 'Exp', values_to = 'LFQValue') %>%
        mutate(Sample = gsub("_TOTALS_", ".", Exp))
    
    violin <- ggplot(data=df, aes(x=Sample, y=LFQValue, fill=Sample))+
        geom_boxplot(width=0.3) +
        geom_violin(alpha=0.4)+
        theme(legend.position = 'none') +
        labs(x=xlab, y=ylab)
    
    return(violin)
}

plotoneviolin <- function(object, xlab) {
    object <- as.data.frame(object) %>%
        pivot_longer(everything(), names_to = 'Sample', values_to = 'LFQ_CV')
    
    ggplot(data=object, aes(x=Sample, y=LFQ_CV, fill=Sample))+
        geom_boxplot(width=0.2)+
        geom_violin(alpha=0.4)+
        labs(title=NULL,x=xlab,y='LFQ CV[%]')+
        theme(legend.position = 'none',
              panel.background = element_rect(fill='white', colour = 'grey'),
              panel.grid = element_line(colour = 'grey'))
}

library(ggplot2)
library(ggpubr)
library(dplyr)
library(tidyr)
library(vsn)
library(protti)
source('EigenMS/EigenMS/EigenMS.R')
```

# Introduction

The results below shows the comparison of several normalization and imputation methods.
We decided to use 4 imputation methods:

1. Shifted Distribution based on the data;
2. Imputation using the Random Forest algorithm;
3. Imputation using the k-Nearest Neighbors algorithm;
4. Imputation using the ludovic method.

and 8 normalization methods:

1. Z-Score Normalization
2. Min-Max Normalization
3. Median Scaling
4. MAD (Median Absolute Deviation) Scaling
5. Linear Regression Normalization
6. VSN (Variance Stabilization Normalization)
7. EigenMS

We used the following parameters for the K-Nearest Neighbors algorithm (bold row):

| k | RMSE | Rsquared | MAE |
|:--:|:--:|:--:|:--:|
| **5** | **560141411** | **0.5764903** | **83499878** |
| 7 | 586141572 | 0.5110148 | 89345187 |
| 9 | 615649021 | 0.4549313 | 93976048 |

For the Random Forest algorithm we used the Grid Search method to find the best hyperparameters.
The table belows shows the output of the top 10 models.

<center><b style='font-size:20px'>GRID SEARCH FOR RANDOM FOREST MODEL</b></center>
<br>

|     | num.trees | mtry | min.node.size | replace | sample.fraction |        rmse         | perc_gain |
|:---:|:---------:|:----:|:-------------:|:-------:|:---------------:|:-------------------:|:---------:|
|**1**|  **100**  | **4**|         **5** |**false**|         **0.8** |  **36184321.6466**  | **2.8631**|
|  2  |       500 |    4 |             5 | false   |            0.8  |    367032968.8757   |     1.4713|
|  3  |       300 |    4 |             5 | false   |            0.8  |    367963900.30284  |     1.2214|
|  4  |       500 |    4 |             1 | true    |            0.8  |    370084110.1524   |     0.6523|
|  5  |       500 |    4 |            10 | false   |            0.8  |    370380581.2619   |     0.5727|
|  6  |       300 |    4 |             1 | true    |           0.63  |    371446664.9562   |     0.2865|
|  7  |       100 |    4 |             5 | false   |            0.8  |    372131148.9947   |     0.1027|
|  8  |       300 |    4 |            10 | false   |            0.8  |    372169999.3198   |     0.0923|
|  9  |       300 |    4 |             4 | true    |           0.63  |    372767670.8139   |    -0.0681|
| 10  |       300 |    4 |             3 | true    |            0.8  |    373586116.5828   |    -0.2878|


Base on the output of the grid search, we can see that there is better model than default and 
it is random forest model with the following hyperparameters:

* num.trees = 100
* mtry = 4
* min.node.size = 5
* replace = FALSE
* sample.fraction = 0.80

For the Ludovic method first we had to assign the missing values using the
[`protti::assign_missingness()`](https://jpquast.github.io/protti/reference/assign_missingness.html) 
fxn, which added the **`comparison`** column containing the comparison name for the specific 
treatment/reference pair and the **`missingness`** column with 4 types of missingness:

* **`"complete"`**: No missing values for every replicate of this reference/treatment 
pair for the specific grouping variable.
* **`"MNAR"`**: Missing not at random. All replicates of either the reference or 
treatment condition have missing values for the specific grouping variable.
* **`"MAR"`**: Missing at random. At least n-1 replicates have missing values for the 
reference/treatment pair for the specific grouping variable.
* **`NA`**: The comparison is not complete enough to fall into any other category. 
It will not be imputed if imputation is performed.

Then with additional column we could enter our data into 
[`protti::impute()`](https://jpquast.github.io/protti/reference/impute.html) 
fxn, which performs the Ludovic imputation method based on the **`missingness`** column
using the following instructions:

* **`"MNAR"`** missingness is sampled from a normal distribution around a value that 
is three lower (log2) than the lowest intensity value recorded for the 
precursor/peptide and that has a spread of the mean standard deviation for the precursor/peptide.
* **`"MAR"`** data is imputed using the mean and variance of the condition with the missing data.
* **`"NA"`** data is not imputed.

```{r load data}
# load raw data
protein.groups <- readr::read_tsv('./data/proteinGroups.txt',show_col_types = FALSE)

protein.groups <- protein.groups %>% filter(is.na(`Only identified by site`),
                         is.na(Reverse),
                         is.na(`Potential contaminant`))

# non-imputed data
lfq <- read.csv('./data/nonimputed_lfq.csv')

# imputed data with Mateusz fxn
lfq_imp <- read.csv('./data/LFQ_raw_totals_imp.csv')
colnames(lfq_imp) <- gsub('_TOTALS_', '.I.', colnames(lfq_imp))
```

```{r nonimp TOTALS data}
# Extracting only TOTALS data for knockout
LFQ_KO <- lfq %>% select(contains('KO'))

# Extracting only TOTALS data for wild type
LFQ_WT <- lfq %>% select(contains('WT'))
```

```{r imp TOTALS data}
# Extracting only TOTALS data for knockout
LFQ_KO_imp <- lfq_imp %>% select(contains('KO'))

# Extracting only TOTALS data for wild type
LFQ_WT_imp <- lfq_imp %>% select(contains('WT'))
```

```{r data to RF and kNN}
# extracting columns to machine learning models
df_ml <- protein.groups |>
    dplyr::select(`Number of proteins`, Peptides, `Sequence coverage [%]`, `Sequence length`, 
                  `Mol. weight [kDa]`, `Q-value`, Score, `MS/MS count`, 
                  dplyr::starts_with('LFQ Intensity') & (ends_with('22') | ends_with('23') | ends_with('24')) & dplyr::contains('TOTALS'))

# changing the colnames
colnames(df_ml)[9:14] <- gsub('LFQ intensity ', '', colnames(df_ml)[9:14])

# making longer data frame with one column containing all LFQ values
df_ml <- df_ml |>
    dplyr::mutate(prot.id = paste('prot',1:nrow(df_ml),sep='_')) |>
    tidyr::pivot_longer(9:14, names_to = 'Sample', values_to = 'LFQvalue') |>
    tidyr::separate(col=Sample, into=c("celltype","sampletype","rep"), sep = "_", remove = FALSE) |>
    dplyr::mutate(celltype = as.factor(celltype), sampletype = as.factor(sampletype),
                  rep = as.factor(rep))

# changing values with 0 to NA
df_ml$LFQvalue[df_ml$LFQvalue==0] <- NA

df_ml$missingness <- assign_missing(df_ml$prot.id, df_ml$celltype, df_ml$LFQvalue)$missingness

# removing blank spaces and all separators from colnames
colnames(df_ml)[1:8] <- c('no.proteins', 'peptides','seq.coverage','seq.len',
                                      'mol.weight.kDa','q.value','score','ms.count')

# Remove unnecessary columns and reordering columns
df_ml.to.models <- df_ml |>
    dplyr::select(-prot.id, -Sample, -sampletype) |> dplyr::select(1:10, 12, 11) |>
    dplyr::mutate(missingness = as.numeric(as.factor(missingness)),
                  celltype = as.numeric(celltype),
                  rep = as.numeric(rep))

df_ml <- df_ml |>
    dplyr::select(-prot.id, -Sample) |> dplyr::select(1:11, 13, 12) |>
    dplyr::mutate(missingness = as.factor(missingness))
```

```{r data to protti}
df_to_protti <- protein.groups %>%
    select(`Protein IDs`, `Peptide sequences`, 
           contains('LFQ intensity') & contains('TOTALS') & (ends_with('22') | ends_with('23') | ends_with('24'))) %>%
    mutate(`Protein IDs`= paste('prot_', 1:nrow(protein.groups), sep='')) %>%
    pivot_longer(3:8, names_to = 'Sample', values_to = 'Intensity')%>%
    mutate(Sample = gsub('LFQ intensity ', '', Sample)) %>%
    mutate(Sample = gsub('_TOTALS_', '_', Sample)) %>%
    separate(col =  Sample, into = c("celltype","rep"), sep = "_", remove = F) %>%
    mutate(Condition = ifelse(celltype == 'KO', 'treated', 'control'),
           Intensity = ifelse(Intensity == 0, NA, log2(Intensity))) %>% 
    select(Sample, `Protein IDs`, `Peptide sequences`, Condition, Intensity) 
```

```{r train/test split}
# creating data with no NA to train models
df_ml.no.na <- na.omit(df_ml.to.models)

# set seed to avoid different models and test/train data with each run
set.seed(123)
# split data to train and test
train_data_idx <- sample(1:nrow(df_ml.no.na), ceiling(0.7*nrow(df_ml.no.na)))
train_data <- df_ml.no.na[train_data_idx,]
```

```{r imputation RF}
# training random forest model
rf.model <- ranger::ranger(LFQvalue ~ .,
                          data=train_data,
                          num.trees = 100,
                          mtry = 4,
                          min.node.size = 5,
                          replace = FALSE,
                          sample.fraction = 0.8,
                          seed = 123,
                          importance = 'impurity')

# extracting missing rows - can be usefull later
missing <- which(is.na(df_ml$LFQvalue))

# predict the values for NA rows
predictions <- predict(rf.model, df_ml.to.models[missing,])

# data frame with predicted LFQ values by random forest model
imputed_RF <- df_ml
imputed_RF[missing,13] <- predictions$predictions
imputed_RF <- imputed_RF |>
    dplyr::select(celltype, rep, LFQvalue) |>
    dplyr::mutate('Batch' = paste(celltype, rep, sep='.'),
                  LFQvalue = log2(LFQvalue)) |>
    dplyr::select(Batch, LFQvalue) |>
    tidyr::pivot_wider(everything(), names_from = Batch, values_from = LFQvalue) |>
    unnest()

# extracting KO and WT
LFQ_KO_RF <- imputed_RF |> dplyr::select(contains('KO'))
LFQ_WT_RF <- imputed_RF |> dplyr::select(contains('WT'))
```

```{r imputation kNN}
# calculating kNN model
kNN.model <- caret::train(LFQvalue ~ ., data=train_data, method='knn')

# predict the values for NA rows
predictions2 <- predict(kNN.model, df_ml.to.models[missing,1:12])

# data frame with predicted LFQ values by random forest model
imputed_kNN <- df_ml
imputed_kNN[missing,13] <- predictions2
imputed_kNN <- imputed_kNN |>
    dplyr::select(celltype, rep, LFQvalue) |>
    dplyr::mutate('Batch' = paste(celltype, rep, sep='.'),
                  LFQvalue = log2(LFQvalue)) |>
    dplyr::select(Batch, LFQvalue) |>
    tidyr::pivot_wider(everything(), names_from = Batch, values_from = LFQvalue) |>
    unnest()

# extracting KO and WT
LFQ_KO_kNN <- imputed_kNN |> dplyr::select(contains('KO'))
LFQ_WT_kNN <- imputed_kNN |> dplyr::select(contains('WT'))
```

```{r ludovic imputation}
data_missing <- df_to_protti |>
    assign_missingness(sample=Sample,
                       condition = Condition,
                       grouping = `Protein IDs`,
                       intensity = Intensity,
                       ref_condition = 'all')

imputed_ludovic <- impute(
    data_missing,
    sample = Sample,
    grouping = `Protein IDs`,
    intensity_log2 = Intensity,
    condition = Condition,
    comparison = comparison,
    missingness = missingness,
    method = 'ludovic',
    skip_log2_transform_error = TRUE
)
rm(data_missing)

# droping the NA values 
imputed_ludovic <- imputed_ludovic[which(!is.na(imputed_ludovic$missingness)),]

# extracting KO and WT
imputed_ludovic <- imputed_ludovic |>
    dplyr::select(Sample, imputed_intensity, `Protein IDs`) |>
    tidyr::pivot_wider(everything(), names_from = Sample, values_from = imputed_intensity) |>
    unnest()

LFQ_KO_ludovic <- imputed_ludovic |> dplyr::select(contains('KO'))
LFQ_WT_ludovic <- imputed_ludovic |> dplyr::select(contains('WT'))
```

# Distributions {.tabset}

**Summary**<br>
Below we can see the distribution of non-imputed data and data imputed with 4 methods:

1. Shifted Distribution based on the data;
2. Imputation using the Random Forest algorithm;
3. Imputation using the k-Nearest Neighbors algorithm;
4. Imputation using the ludovic method.

For each histogram, we can see that the 24th replicate (blue colour) of the KO 
cell type  has a distribution shift to the right. Our goal is to get this 
distribution closer to the others, and we can do this using different 
normalization methods.

## Mati Code

```{r distributions mati code}
ggarrange(
    plothist(LFQ_KO, '', FALSE) + xlab('KO') + ggtitle('Non-Imputed'), 
    plothist(LFQ_WT, '', FALSE) + xlab('WT') + ggtitle(''),
    plothist(LFQ_KO_imp, '', FALSE) + xlab('KO') + ggtitle('Imputed'), 
    plothist(LFQ_WT_imp, '', FALSE) + xlab('WT') + ggtitle(''),
    nrow=2,ncol=2
)
```

## Random Forest

```{r distribution rf}
ggarrange(
    plothist(LFQ_KO, '', FALSE) + xlab('KO') + ggtitle('Non-Imputed'), 
    plothist(LFQ_WT, '', FALSE) + xlab('WT') + ggtitle(''),
    plothist(LFQ_KO_RF, '', FALSE) + xlab('KO') + ggtitle('Imputed - Random Forest'), 
    plothist(LFQ_WT_RF, '', FALSE) + xlab('WT') + ggtitle(''),
    nrow=2,ncol=2
)
```

## k-Nearest Neighbors

```{r distribution kNN}
ggarrange(
    plothist(LFQ_KO, '', FALSE) + xlab('KO') + ggtitle('Non-Imputed'), 
    plothist(LFQ_WT, '', FALSE) + xlab('WT') + ggtitle(''),
    plothist(LFQ_KO_kNN, '', FALSE) + xlab('KO') + ggtitle('Imputed - kNN'), 
    plothist(LFQ_WT_kNN, '', FALSE) + xlab('WT') + ggtitle(''),
    nrow=2,ncol=2
)
```

## Ludovic

```{r distribution ludovic}
ggarrange(
    plothist(LFQ_KO, '', FALSE) + xlab('KO') + ggtitle('Non-Imputed'), 
    plothist(LFQ_WT, '', FALSE) + xlab('WT') + ggtitle(''),
    plothist(LFQ_KO_ludovic, '', FALSE) + xlab('KO') + ggtitle('Imputed - Ludovic'), 
    plothist(LFQ_WT_ludovic, '', FALSE) + xlab('WT') + ggtitle(''),
    nrow=2,ncol=2
)
```

# Normalization {.tabset}

The 24th replicate of the KO cell type has the distribution shifted to the right and 
should be more similar to the other replicates. Therefore we tried several
normalization methods to achieve this goal. We used the following methods:

1. Z-Score
2. Min-Max
3. Median Scaling
4. MAD (Median Absolute Deviation) Scaling
5. Linear Regression
6. VSN (Variance Stabilization Normalization)
7. EigenMS

## Z-Score

Z-score normalization standardizes data by subtracting the mean and dividing 
by the standard deviation. This technique transforms data into a distribution 
with a mean of 0 and a standard deviation of 1.

Formula: $\tilde{y}_{ij} = \frac{y_ij - \bar{y_j}}{\theta_j}$, where:

* $y_ij$ - value of the LFQ;
* $\bar{y_j}$ - mean of the LFQ values;
* $\theta_j$ - standard deviation of the LFQ values.

```{r KO standardization}
LFQ_KO.standard <- as.data.frame(scale(LFQ_KO)) # Non-Imputed
LFQ_KO_imp.standard <- as.data.frame(scale(LFQ_KO_imp)) # Imputed - Mati Code
LFQ_KO_RF.standard <- as.data.frame(scale(LFQ_KO_RF)) # Imputed RF
LFQ_KO_kNN.standard <- as.data.frame(scale(LFQ_KO_kNN)) # Imputed kNN
LFQ_KO_ludovic.standard <- as.data.frame(scale(LFQ_KO_ludovic)) # Imputed ludovic
```

```{r WT standardization}
LFQ_WT.standard <- as.data.frame(scale(LFQ_WT)) # Non-Imputed
LFQ_WT_imp.standard <- as.data.frame(scale(LFQ_WT_imp)) # Imputed - Mati Code
LFQ_WT_RF.standard <- as.data.frame(scale(LFQ_WT_RF)) # Imputed RF
LFQ_WT_kNN.standard <- as.data.frame(scale(LFQ_WT_kNN)) # Imputed kNN
LFQ_WT_ludovic.standard <- as.data.frame(scale(LFQ_WT_ludovic)) # Imputed ludovic
```

---

<center><b style='font-size:26px'>DISTRIBUTIONS</b></center>

---

```{r dist standardization, fig.height=4}
annotate_figure(ggarrange(
    plothist(LFQ_KO.standard, NULL, TRUE) + xlab('KO'), 
    plothist(LFQ_WT.standard, NULL, TRUE) + xlab('WT'),
    nrow=1,ncol=2
    ), top = text_grob('Non-Imputed Data', size = 16)
)
```

```{r}
ggarrange(
    annotate_figure(ggarrange(
        plothist(LFQ_KO_imp.standard, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_imp.standard, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Mati Code', size = 16)
    ),
    annotate_figure(ggarrange(
        plothist(LFQ_KO_RF.standard, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_RF.standard, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Random Forest', size = 16)
    ),
    nrow=2,ncol=1
)
ggarrange(
    annotate_figure(ggarrange(
        plothist(LFQ_KO_kNN.standard, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_kNN.standard, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - kNN', size = 16)
    ),
    annotate_figure(ggarrange(
        plothist(LFQ_KO_ludovic.standard, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_ludovic.standard, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Ludovic', size = 16)
    ),
    nrow=2,ncol=1
)
```

**Summary** <br>
The Z-SCORE method brought the distribution closer together, but we lost
the original scale of the data and the differences are harder to see after normalization.

## Min-Max

Min-max normalization scales data to a specified range (usually [0, 1]) by 
subtracting the minimum value and dividing by the range of values.

```{r minmax}
min_max_norm <- function(df) {
    df_no_na <- na.omit(df)
    ret <- scale(df_no_na, center = min(df_no_na), scale = max(df_no_na) - min(df_no_na))
    df[which(!is.na(df))] <- ret
    return(df)
}

LFQ_KO.minmax <- as.data.frame(lapply(LFQ_KO, function(col) min_max_norm(col)))  # Non-Imputed
LFQ_KO_imp.minmax <- as.data.frame(lapply(LFQ_KO_imp, function(col) min_max_norm(col)))  # Imputed
LFQ_KO_RF.minmax <- as.data.frame(lapply(LFQ_KO_RF, function(col) min_max_norm(col)))  # Imputed RF
LFQ_KO_kNN.minmax <- as.data.frame(lapply(LFQ_KO_kNN, function(col) min_max_norm(col)))  # Imputed kNN
LFQ_KO_ludovic.minmax <- as.data.frame(lapply(LFQ_KO_ludovic, function(col) min_max_norm(col)))  # Imputed ludovic

LFQ_WT.minmax <- as.data.frame(lapply(LFQ_WT, function(col) min_max_norm(col)))  # Non-Imputed
LFQ_WT_imp.minmax <- as.data.frame(lapply(LFQ_WT_imp, function(col) min_max_norm(col)))  # Imputed
LFQ_WT_RF.minmax <- as.data.frame(lapply(LFQ_WT_RF, function(col) min_max_norm(col)))  # Imputed RF
LFQ_WT_kNN.minmax <- as.data.frame(lapply(LFQ_WT_kNN, function(col) min_max_norm(col)))  # Imputed kNN
LFQ_WT_ludovic.minmax <- as.data.frame(lapply(LFQ_WT_ludovic, function(col) min_max_norm(col)))  # Imputed ludovic
```

---

<center><b style='font-size:26px'>DISTRIBUTIONS</b></center>

---

```{r dist minmax, fig.height=4}
annotate_figure(ggarrange(
    plothist(LFQ_KO.minmax, NULL, TRUE) + xlab('KO'), 
    plothist(LFQ_WT.minmax, NULL, TRUE) + xlab('WT'),
    nrow=1,ncol=2
    ), top = text_grob('Non-Imputed Data', size = 16)
)
```

```{r}
ggarrange(
    annotate_figure(ggarrange(
        plothist(LFQ_KO_imp.minmax, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_imp.minmax, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Mati Code', size = 16)
    ),
    annotate_figure(ggarrange(
        plothist(LFQ_KO_RF.minmax, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_RF.minmax, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Random Forest', size = 16)
    ),
    nrow=2,ncol=1
)

ggarrange(
    annotate_figure(ggarrange(
        plothist(LFQ_KO_kNN.minmax, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_kNN.minmax, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - kNN', size = 16)
    ),
    annotate_figure(ggarrange(
        plothist(LFQ_KO_ludovic.minmax, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_ludovic.minmax, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Ludovic', size = 16)
    ),
    nrow=2,ncol=1
)
```

**Summary** <br>
The MIN-MAX method didn't succeed in bringing the distribution closer together. 
In conclusion, we probably shouldn't use this method.

## Median Scaling

```{r median scaling}
LFQ_KO.med <- as.data.frame(DescTools::RobScale(LFQ_KO, scale=FALSE)) # Non-Imputed
LFQ_KO_imp.med <- as.data.frame(DescTools::RobScale(LFQ_KO_imp, scale=FALSE)) # Imputed
LFQ_KO_RF.med <- as.data.frame(DescTools::RobScale(LFQ_KO_RF, scale=FALSE)) # Imputed
LFQ_KO_kNN.med <- as.data.frame(DescTools::RobScale(LFQ_KO_kNN, scale=FALSE)) # Imputed
LFQ_KO_ludovic.med <- as.data.frame(DescTools::RobScale(LFQ_KO_ludovic, scale=FALSE)) # Imputed

LFQ_WT.med <- as.data.frame(DescTools::RobScale(LFQ_WT, scale=FALSE)) # Non-Imputed
LFQ_WT_imp.med <- as.data.frame(DescTools::RobScale(LFQ_WT_imp, scale=FALSE)) # Imputed
LFQ_WT_RF.med <- as.data.frame(DescTools::RobScale(LFQ_WT_RF, scale=FALSE)) # Imputed
LFQ_WT_kNN.med <- as.data.frame(DescTools::RobScale(LFQ_WT_kNN, scale=FALSE)) # Imputed
LFQ_WT_ludovic.med <- as.data.frame(DescTools::RobScale(LFQ_WT_ludovic, scale=FALSE)) # Imputed
```

---

<center><b style='font-size:26px'>DISTRIBUTIONS</b></center>

---

```{r dist median, fig.height=4}
annotate_figure(ggarrange(
    plothist(LFQ_KO.med, NULL, TRUE) + xlab('KO'), 
    plothist(LFQ_WT.med, NULL, TRUE) + xlab('WT'),
    nrow=1,ncol=2
    ), top = text_grob('Non-Imputed Data', size = 16)
)
```

```{r}
ggarrange(
    annotate_figure(ggarrange(
        plothist(LFQ_KO_imp.med, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_imp.med, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Mati Code', size = 16)
    ),
    annotate_figure(ggarrange(
        plothist(LFQ_KO_RF.med, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_RF.med, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Random Forest', size = 16)
    ),
    nrow=2,ncol=1
)

ggarrange(
    annotate_figure(ggarrange(
        plothist(LFQ_KO_kNN.med, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_kNN.med, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - kNN', size = 16)
    ),
    annotate_figure(ggarrange(
        plothist(LFQ_KO_ludovic.med, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_ludovic.med, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Ludovic', size = 16)
    ),
    nrow=2,ncol=1
)
```

**Summary**<br>
The MEDIAN scaling method brought the distributions closer together, but again we lost
the original scale of the data and the differences are harder to see after normalization.

## MAD Scaling

```{r mad scaling}
LFQ_KO.mad <- as.data.frame(DescTools::RobScale(LFQ_KO)) # Non-Imputed
LFQ_KO_imp.mad <- as.data.frame(DescTools::RobScale(LFQ_KO_imp)) # Imputed
LFQ_KO_RF.mad <- as.data.frame(DescTools::RobScale(LFQ_KO_RF)) # Imputed RF
LFQ_KO_kNN.mad <- as.data.frame(DescTools::RobScale(LFQ_KO_kNN)) # Imputed kNN
LFQ_KO_ludovic.mad <- as.data.frame(DescTools::RobScale(LFQ_KO_ludovic)) # Imputed ludovic

LFQ_WT.mad <- as.data.frame(DescTools::RobScale(LFQ_WT)) # Non-Imputed
LFQ_WT_imp.mad <- as.data.frame(DescTools::RobScale(LFQ_WT_imp)) # Imputed
LFQ_WT_RF.mad <- as.data.frame(DescTools::RobScale(LFQ_WT_RF)) # Imputed RF
LFQ_WT_kNN.mad <- as.data.frame(DescTools::RobScale(LFQ_WT_kNN)) # Imputed kNN
LFQ_WT_ludovic.mad <- as.data.frame(DescTools::RobScale(LFQ_WT_ludovic)) # Imputed ludovic
```

---

<center><b style='font-size:26px'>DISTRIBUTIONS</b></center>

---

```{r dist mad, fig.height=4}
annotate_figure(ggarrange(
    plothist(LFQ_KO.mad, NULL, TRUE) + xlab('KO'), 
    plothist(LFQ_WT.mad, NULL, TRUE) + xlab('WT'),
    nrow=1,ncol=2
    ), top = text_grob('Non-Imputed Data', size = 16)
)
```

```{r}
ggarrange(
    annotate_figure(ggarrange(
        plothist(LFQ_KO_imp.mad, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_imp.mad, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Mati Code', size = 16)
    ),
    annotate_figure(ggarrange(
        plothist(LFQ_KO_RF.mad, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_RF.mad, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Random Forest', size = 16)
    ),
    nrow=2,ncol=1
)

ggarrange(
    annotate_figure(ggarrange(
        plothist(LFQ_KO_kNN.mad, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_kNN.mad, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - kNN', size = 16)
    ),
    annotate_figure(ggarrange(
        plothist(LFQ_KO_ludovic.mad, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_ludovic.mad, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Ludovic', size = 16)
    ),
    nrow=2,ncol=1
)
```

**Summary**<br>
The MAD scaling method brought the distributions closer together, but again we lost
the original scale of the data and the differences are harder to see after normalization.

## Linear Regression

```{r KO lm}
# Non-Imputed
LFQ_KO_long <- LFQ_KO %>%
    pivot_longer(cols = 1:3, names_to = "Batch", values_to = "LFQValue")

model <- lm(LFQValue ~ Batch, data=LFQ_KO_long)
LFQ_KO_long$normalized <- NA
LFQ_KO_long[which(!is.na(LFQ_KO_long$LFQValue)), 'normalized'] <- residuals(model)

LFQ_KO.lm <- LFQ_KO_long %>% 
    mutate(row = rep(1:nrow(LFQ_KO), each=3)) %>%
    reshape2::dcast(row ~ Batch, value.var='normalized') %>%
    select(-row)

# Imputed Mati Code
LFQ_KO_long <- LFQ_KO_imp %>%
    pivot_longer(cols = 1:3, names_to = "Batch", values_to = "LFQValue")

model <- lm(LFQValue ~ Batch, data=LFQ_KO_long)
LFQ_KO_long$normalized <- residuals(model)

LFQ_KO_imp.lm <- LFQ_KO_long %>% 
    mutate(row = rep(1:nrow(LFQ_KO_imp), each=3)) %>%
    reshape2::dcast(row ~ Batch, value.var='normalized') %>%
    select(-row)

# Imputed RF
LFQ_KO_long <- LFQ_KO_RF %>%
    pivot_longer(cols = 1:3, names_to = "Batch", values_to = "LFQValue")

model <- lm(LFQValue ~ Batch, data=LFQ_KO_long)
LFQ_KO_long$normalized <- residuals(model)

LFQ_KO_RF.lm <- LFQ_KO_long %>% 
    mutate(row = rep(1:nrow(LFQ_KO_RF), each=3)) %>%
    reshape2::dcast(row ~ Batch, value.var='normalized') %>%
    select(-row)

# Imputed kNN
LFQ_KO_long <- LFQ_KO_kNN %>%
    pivot_longer(cols = 1:3, names_to = "Batch", values_to = "LFQValue")

model <- lm(LFQValue ~ Batch, data=LFQ_KO_long)
LFQ_KO_long$normalized <- residuals(model)

LFQ_KO_kNN.lm <- LFQ_KO_long %>% 
    mutate(row = rep(1:nrow(LFQ_KO_kNN), each=3)) %>%
    reshape2::dcast(row ~ Batch, value.var='normalized') %>%
    select(-row)

# Imputed ludovic
LFQ_KO_long <- LFQ_KO_ludovic %>%
    pivot_longer(cols = 1:3, names_to = "Batch", values_to = "LFQValue")

model <- lm(LFQValue ~ Batch, data=LFQ_KO_long)
LFQ_KO_long$normalized <- residuals(model)

LFQ_KO_ludovic.lm <- LFQ_KO_long %>% 
    mutate(row = rep(1:nrow(LFQ_KO_ludovic), each=3)) %>%
    reshape2::dcast(row ~ Batch, value.var='normalized') %>%
    select(-row)
```

```{r WT lm}
# Non-Imputed
LFQ_WT_long <- LFQ_WT %>%
    pivot_longer(cols = 1:3, names_to = "Batch", values_to = "LFQValue")

model <- lm(LFQValue ~ Batch, data=LFQ_WT_long)
LFQ_WT_long$normalized <- NA
LFQ_WT_long[which(!is.na(LFQ_WT_long$LFQValue)), 'normalized'] <- residuals(model)

LFQ_WT.lm <- LFQ_WT_long %>% 
    mutate(row = rep(1:nrow(LFQ_WT), each=3)) %>%
    reshape2::dcast(row ~ Batch, value.var='normalized') %>%
    select(-row)

# Imputed Mati Code
LFQ_WT_long <- LFQ_WT_imp %>%
    pivot_longer(cols = 1:3, names_to = "Batch", values_to = "LFQValue")

model <- lm(LFQValue ~ Batch, data=LFQ_WT_long)
LFQ_WT_long$normalized <- residuals(model)

LFQ_WT_imp.lm <- LFQ_WT_long %>% 
    mutate(row = rep(1:nrow(LFQ_WT_imp), each=3)) %>%
    reshape2::dcast(row ~ Batch, value.var='normalized') %>%
    select(-row)

# Imputed RF
LFQ_WT_long <- LFQ_WT_RF %>%
    pivot_longer(cols = 1:3, names_to = "Batch", values_to = "LFQValue")

model <- lm(LFQValue ~ Batch, data=LFQ_WT_long)
LFQ_WT_long$normalized <- residuals(model)

LFQ_WT_RF.lm <- LFQ_WT_long %>% 
    mutate(row = rep(1:nrow(LFQ_WT_RF), each=3)) %>%
    reshape2::dcast(row ~ Batch, value.var='normalized') %>%
    select(-row)

# Imputed kNN
LFQ_WT_long <- LFQ_WT_kNN %>%
    pivot_longer(cols = 1:3, names_to = "Batch", values_to = "LFQValue")

model <- lm(LFQValue ~ Batch, data=LFQ_WT_long)
LFQ_WT_long$normalized <- residuals(model)

LFQ_WT_kNN.lm <- LFQ_WT_long %>% 
    mutate(row = rep(1:nrow(LFQ_WT_kNN), each=3)) %>%
    reshape2::dcast(row ~ Batch, value.var='normalized') %>%
    select(-row)

# Imputed ludovic
LFQ_WT_long <- LFQ_WT_ludovic %>%
    pivot_longer(cols = 1:3, names_to = "Batch", values_to = "LFQValue")

model <- lm(LFQValue ~ Batch, data=LFQ_WT_long)
LFQ_WT_long$normalized <- residuals(model)

LFQ_WT_ludovic.lm <- LFQ_WT_long %>% 
    mutate(row = rep(1:nrow(LFQ_WT_ludovic), each=3)) %>%
    reshape2::dcast(row ~ Batch, value.var='normalized') %>%
    select(-row)
```

---

<center><b style='font-size:26px'>DISTRIBUTIONS</b></center>

---

```{r dist lm, fig.height=4}
annotate_figure(ggarrange(
    plothist(LFQ_KO.lm, NULL, TRUE) + xlab('KO'), 
    plothist(LFQ_WT.lm, NULL, TRUE) + xlab('WT'),
    nrow=1,ncol=2
    ), top = text_grob('Non-Imputed Data', size = 16)
)
```

```{r}
ggarrange(
    annotate_figure(ggarrange(
        plothist(LFQ_KO_imp.lm, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_imp.lm, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Mati Code', size = 16)
    ),
    annotate_figure(ggarrange(
        plothist(LFQ_KO_RF.lm, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_RF.lm, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Random Forest', size = 16)
    ),
    nrow=2,ncol=1
)

ggarrange(
    annotate_figure(ggarrange(
        plothist(LFQ_KO_kNN.lm, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_kNN.lm, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - kNN', size = 16)
    ),
    annotate_figure(ggarrange(
        plothist(LFQ_KO_ludovic.lm, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_ludovic.lm, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Ludovic', size = 16)
    ),
    nrow=2,ncol=1
)
```

**Summary**<br>
The linear regression method brought the distributions closer together, but again we lost
the original scale of the data and the differences are harder to see after normalization.

## VSN

```{r vsn}
lfq_rglist<- new('RGList', list(
    R = as.matrix(LFQ_KO),
    G = as.matrix(LFQ_WT)))

lfq_rglist_imp<- new('RGList', list(
    R = as.matrix(LFQ_KO_imp),
    G = as.matrix(LFQ_WT_imp)))

lfq_rglist_RF<- new('RGList', list(
    R = as.matrix(LFQ_KO_RF),
    G = as.matrix(LFQ_WT_RF)))

lfq_rglist_kNN<- new('RGList', list(
    R = as.matrix(LFQ_KO_kNN),
    G = as.matrix(LFQ_WT_kNN)))

lfq_rglist_ludovic <- new('RGList', list(
    R = as.matrix(LFQ_KO_ludovic),
    G = as.matrix(LFQ_WT_ludovic)))

LFQ_KO.vsn <- justvsn(lfq_rglist)@assayData$R  # Non-Imputed
LFQ_KO_imp.vsn <- justvsn(lfq_rglist_imp)@assayData$R # Imputed
LFQ_KO_RF.vsn <- justvsn(lfq_rglist_RF)@assayData$R # Imputed RF
LFQ_KO_kNN.vsn <- justvsn(lfq_rglist_kNN)@assayData$R # Imputed kNN
LFQ_KO_ludovic.vsn <- justvsn(lfq_rglist_ludovic)@assayData$R # Imputed ludovic

LFQ_WT.vsn <- justvsn(lfq_rglist)@assayData$G  # Non-Imputed
LFQ_WT_imp.vsn <- justvsn(lfq_rglist_imp)@assayData$G # Imputed
LFQ_WT_RF.vsn <- justvsn(lfq_rglist_RF)@assayData$G # Imputed RF
LFQ_WT_kNN.vsn <- justvsn(lfq_rglist_kNN)@assayData$G # Imputed kNN
LFQ_WT_ludovic.vsn <- justvsn(lfq_rglist_ludovic)@assayData$G # Imputed ludovic
```

---

<center><b style='font-size:26px'>DISTRIBUTIONS</b></center>

---

```{r dist vsn, fig.height=4}
annotate_figure(ggarrange(
    plothist(LFQ_KO.vsn, NULL, TRUE) + xlab('KO'), 
    plothist(LFQ_WT.vsn, NULL, TRUE) + xlab('WT'),
    nrow=1,ncol=2
    ), top = text_grob('Non-Imputed Data', size = 16)
)
```

```{r}
ggarrange(
    annotate_figure(ggarrange(
        plothist(LFQ_KO_imp.vsn, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_imp.vsn, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Mati Code', size = 16)
    ),
    annotate_figure(ggarrange(
        plothist(LFQ_KO_RF.vsn, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_RF.vsn, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Random Forest', size = 16)
    ),
    nrow=2,ncol=1
)

ggarrange(
    annotate_figure(ggarrange(
        plothist(LFQ_KO_kNN.vsn, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_kNN.vsn, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - kNN', size = 16)
    ),
    annotate_figure(ggarrange(
        plothist(LFQ_KO_ludovic.vsn, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_ludovic.vsn, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Ludovic', size = 16)
    ),
    nrow=2,ncol=1
)
```

**Summary**<br>
The VSN method brought the distributions closer together except data imputed 
with ludovic method, but again we lost the original scale of the data and the 
differences are harder to see after normalization. In addition, in all plots the 
24th replicate stands out from the other replicates.

## EigenMS

```{r EigenMS, fig.keep='none', results='hide'}
treatment = as.factor(c('KO', 'KO', 'KO', 'WT', 'WT', 'WT'))
# Non-Imputed
prot.info <- data.frame(prot_ID = paste('prot_', 1:nrow(lfq), sep = ''))
LFQ.eig1 <- eig_norm1(lfq, 
                      treatment = treatment, 
                      prot.info = prot.info)
# Performing eig normalization
LFQ.eig_norm <- eig_norm2(LFQ.eig1)

# Imputed
prot.info <- data.frame(prot_ID = paste('prot_', 1:nrow(lfq_imp), sep = ''))
LFQ_imp.eig1 <- eig_norm1(lfq_imp, 
                          treatment = treatment, 
                          prot.info = prot.info)
# Performing eig normalization
LFQ_imp.eig_norm <- eig_norm2(LFQ_imp.eig1)

# Imputed RF
prot.info <- data.frame(prot_ID = paste('prot_', 1:nrow(imputed_RF), sep = ''))
LFQ_RF.eig1 <- eig_norm1(imputed_RF, 
                         treatment = treatment, 
                         prot.info = prot.info)
# Performing eig normalization
LFQ_RF.eig_norm <- eig_norm2(LFQ_RF.eig1)

# Imputed kNN
prot.info <- data.frame(prot_ID = paste('prot_', 1:nrow(imputed_kNN), sep = ''))
LFQ_kNN.eig1 <- eig_norm1(imputed_kNN, 
                          treatment = treatment, 
                          prot.info = prot.info)
# Performing eig normalization
LFQ_kNN.eig_norm <- eig_norm2(LFQ_kNN.eig1)

# Imputed ludovic
prot.info <- data.frame(imputed_ludovic$`Protein IDs`)
LFQ_ludovic.eig1 <- eig_norm1(imputed_ludovic[,-1],
                              treatment = treatment,
                              prot.info = prot.info)
# Performing eig normalization
LFQ_ludovic.eig_norm <- eig_norm2(LFQ_ludovic.eig1)
```

```{r KO and WT eigen}
LFQ_KO.eigen <- LFQ.eig_norm$norm_m[,1:3] # Non-Imputed
LFQ_KO_imp.eigen <- LFQ_imp.eig_norm$norm_m[,1:3] # Imputed Mati Code
LFQ_KO_RF.eigen <- LFQ_RF.eig_norm$norm_m[,1:3] # Imputed RF
LFQ_KO_kNN.eigen <- LFQ_kNN.eig_norm$norm_m[,1:3] # Imputed kNN
LFQ_KO_ludovic.eigen <- LFQ_ludovic.eig_norm$norm_m[,1:3] # Imputed ludovic

LFQ_WT.eigen <- LFQ.eig_norm$norm_m[,4:6] # Non-Imputed
LFQ_WT_imp.eigen <- LFQ_imp.eig_norm$norm_m[,4:6] # Imputed Mati Code
LFQ_WT_RF.eigen <- LFQ_RF.eig_norm$norm_m[,4:6] # Imputed RF
LFQ_WT_kNN.eigen <- LFQ_kNN.eig_norm$norm_m[,4:6] # Imputed kNN
LFQ_WT_ludovic.eigen <- LFQ_ludovic.eig_norm$norm_m[,4:6] # Imputed ludovic
```

---

<center><b style='font-size:26px'>DISTRIBUTIONS</b></center>

---

```{r dist eigen, fig.height=4}
annotate_figure(ggarrange(
    plothist(LFQ_KO.eigen, NULL, TRUE) + xlab('KO'), 
    plothist(LFQ_WT.eigen, NULL, TRUE) + xlab('WT'),
    nrow=1,ncol=2
    ), top = text_grob('Non-Imputed Data', size = 16)
)
```

```{r}
ggarrange(
    annotate_figure(ggarrange(
        plothist(LFQ_KO_imp.eigen, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_imp.eigen, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Mati Code', size = 16)
    ),
    annotate_figure(ggarrange(
        plothist(LFQ_KO_RF.eigen, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_RF.eigen, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Random Forest', size = 16)
    ),
    nrow=2,ncol=1
)

ggarrange(
    annotate_figure(ggarrange(
        plothist(LFQ_KO_kNN.eigen, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_kNN.eigen, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - kNN', size = 16)
    ),
    annotate_figure(ggarrange(
        plothist(LFQ_KO_ludovic.eigen, '', FALSE) + xlab('KO'), 
        plothist(LFQ_WT_ludovic.eigen, '', FALSE) + xlab('WT'),
        nrow=1,ncol=2
        ), top = text_grob('Imputed Data - Ludovic', size = 16)
    ),
    nrow=2,ncol=1
)
```

**Summary**<br>
The EigenMS method was the only one which kept the differences between the replicates 
and cell types (KO and WT). The distribution are close together and we solve the 
problem of 24th replicate. In my opinion the EigenMS method gives the best results.

# Statistics Metrics {.tabset}

## CV {.tabset}

**COEFFICIENT OF VARIATION (CV) / RELATIVE STANDARD DEVIATION (RSD)**

This is a way to measure how spread out values are in a dataset relative to the mean.
A lower RSD/CV indicates better normalization. It is calculated as:

$CV = \frac{\sigma}{\mu}$

where:

* $\sigma$: The standard deviation of dataset
* $\mu$: The mean of dataset

```{r CV}
cv <- function (x) sd(x) / mean(x) * 100
```

### Non-Imputed

```{r CV1}
cv.before <- data.frame(KO=apply(2^LFQ_KO, 1, cv), WT=apply(2^LFQ_WT,1,cv))
cv.standard <- data.frame(KO=apply(2^LFQ_KO.standard, 1, cv), WT=apply(2^LFQ_WT.standard, 1, cv))
cv.minmax <- data.frame(KO=apply(2^LFQ_KO.minmax, 1, cv), WT= apply(2^LFQ_WT.minmax, 1, cv))
cv.med <- data.frame(KO=apply(2^LFQ_KO.med, 1, cv), WT=apply(2^LFQ_WT.med, 1, cv))
cv.mad <- data.frame(KO=apply(2^LFQ_KO.mad, 1, cv), WT=apply(2^LFQ_WT.mad, 1, cv))
cv.lm <- data.frame(KO=apply(2^LFQ_KO.lm, 1, cv), WT=apply(2^LFQ_WT.lm, 1, cv))
cv.vsn <- data.frame(KO=apply(2^LFQ_KO.vsn, 1, cv), WT=apply(2^LFQ_WT.vsn, 1, cv))
cv.eig <- data.frame(KO=apply(2^LFQ_KO.eigen, 1, cv), WT=apply(2^LFQ_WT.eigen, 1, cv))

ggarrange(
    plotoneviolin(cv.before, 'Original'),
    plotoneviolin(cv.standard, 'Z-Score'),
    plotoneviolin(cv.minmax, 'Min-Max'),
    plotoneviolin(cv.med, 'Median Scaling'),
    nrow=2,ncol=2
)

ggarrange(
    plotoneviolin(cv.mad, 'MAD Scaling'),
    plotoneviolin(cv.lm, 'Linear Regression'),
    plotoneviolin(cv.vsn, 'VSN'),
    plotoneviolin(cv.eig, 'EigenMS'),
    nrow=2,ncol=2
)
```

### Mati Code

```{r CV2}
cv_imp.before <- data.frame(KO=apply(2^LFQ_KO_imp, 1, cv), WT=apply(2^LFQ_WT_imp,1,cv))
cv_imp.standard <- data.frame(KO=apply(2^LFQ_KO_imp.standard, 1, cv), WT=apply(2^LFQ_WT_imp.standard, 1, cv))
cv_imp.minmax <- data.frame(KO=apply(2^LFQ_KO_imp.minmax, 1, cv), WT= apply(2^LFQ_WT_imp.minmax, 1, cv))
cv_imp.med <- data.frame(KO=apply(2^LFQ_KO_imp.med, 1, cv), WT=apply(2^LFQ_WT_imp.med, 1, cv))
cv_imp.mad <- data.frame(KO=apply(2^LFQ_KO_imp.mad, 1, cv), WT=apply(2^LFQ_WT_imp.mad, 1, cv))
cv_imp.lm <- data.frame(KO=apply(2^LFQ_KO_imp.lm, 1, cv), WT=apply(2^LFQ_WT_imp.lm, 1, cv))
cv_imp.vsn <- data.frame(KO=apply(2^LFQ_KO_imp.vsn, 1, cv), WT=apply(2^LFQ_WT_imp.vsn, 1, cv))
cv_imp.eig <- data.frame(KO=apply(2^LFQ_KO_imp.eigen, 1, cv), WT=apply(2^LFQ_WT_imp.eigen, 1, cv))

ggarrange(
    plotoneviolin(cv_imp.before, 'Original'),
    plotoneviolin(cv_imp.standard, 'Z-Score'),
    plotoneviolin(cv_imp.minmax, 'Min-Max'),
    plotoneviolin(cv_imp.med, 'Median Scaling'),
    nrow=2,ncol=2
)

ggarrange(
    plotoneviolin(cv_imp.mad, 'MAD Scaling'),
    plotoneviolin(cv_imp.lm, 'Linear Regression'),
    plotoneviolin(cv_imp.vsn, 'VSN'),
    plotoneviolin(cv_imp.eig, 'EigenMS'),
    nrow=2,ncol=2
)
```

### Random Forest

```{r CV3}
cv_RF.before <- data.frame(KO=apply(2^LFQ_KO_RF, 1, cv), WT=apply(2^LFQ_WT_RF,1,cv))
cv_RF.standard <- data.frame(KO=apply(2^LFQ_KO_RF.standard, 1, cv), WT=apply(2^LFQ_WT_RF.standard, 1, cv))
cv_RF.minmax <- data.frame(KO=apply(2^LFQ_KO_RF.minmax, 1, cv), WT= apply(2^LFQ_WT_RF.minmax, 1, cv))
cv_RF.med <- data.frame(KO=apply(2^LFQ_KO_RF.med, 1, cv), WT=apply(2^LFQ_WT_RF.med, 1, cv))
cv_RF.mad <- data.frame(KO=apply(2^LFQ_KO_RF.mad, 1, cv), WT=apply(2^LFQ_WT_RF.mad, 1, cv))
cv_RF.lm <- data.frame(KO=apply(2^LFQ_KO_RF.lm, 1, cv), WT=apply(2^LFQ_WT_RF.lm, 1, cv))
cv_RF.vsn <- data.frame(KO=apply(2^LFQ_KO_RF.vsn, 1, cv), WT=apply(2^LFQ_WT_RF.vsn, 1, cv))
cv_RF.eig <- data.frame(KO=apply(2^LFQ_KO_RF.eigen, 1, cv), WT=apply(2^LFQ_WT_RF.eigen, 1, cv))

ggarrange(
    plotoneviolin(cv_RF.before, 'Original'),
    plotoneviolin(cv_RF.standard, 'Z-Score'),
    plotoneviolin(cv_RF.minmax, 'Min-Max'),
    plotoneviolin(cv_RF.med, 'Median Scaling'),
    nrow=2,ncol=2
)

ggarrange(
    plotoneviolin(cv_RF.mad, 'MAD Scaling'),
    plotoneviolin(cv_RF.lm, 'Linear Regression'),
    plotoneviolin(cv_RF.vsn, 'VSN'),
    plotoneviolin(cv_RF.eig, 'EigenMS'),
    nrow=2,ncol=2
)
```

### K-Nearest Neighbors

```{r CV4}
cv_kNN.before <- data.frame(KO=apply(2^LFQ_KO_kNN, 1, cv), WT=apply(2^LFQ_WT_kNN,1,cv))
cv_kNN.standard <- data.frame(KO=apply(2^LFQ_KO_kNN.standard, 1, cv), WT=apply(2^LFQ_WT_kNN.standard, 1, cv))
cv_kNN.minmax <- data.frame(KO=apply(2^LFQ_KO_kNN.minmax, 1, cv), WT= apply(2^LFQ_WT_kNN.minmax, 1, cv))
cv_kNN.med <- data.frame(KO=apply(2^LFQ_KO_kNN.med, 1, cv), WT=apply(2^LFQ_WT_kNN.med, 1, cv))
cv_kNN.mad <- data.frame(KO=apply(2^LFQ_KO_kNN.mad, 1, cv), WT=apply(2^LFQ_WT_kNN.mad, 1, cv))
cv_kNN.lm <- data.frame(KO=apply(2^LFQ_KO_kNN.lm, 1, cv), WT=apply(2^LFQ_WT_kNN.lm, 1, cv))
cv_kNN.vsn <- data.frame(KO=apply(2^LFQ_KO_kNN.vsn, 1, cv), WT=apply(2^LFQ_WT_kNN.vsn, 1, cv))
cv_kNN.eig <- data.frame(KO=apply(2^LFQ_KO_kNN.eigen, 1, cv), WT=apply(2^LFQ_WT_kNN.eigen, 1, cv))

ggarrange(
    plotoneviolin(cv_kNN.before, 'Original'),
    plotoneviolin(cv_kNN.standard, 'Z-Score'),
    plotoneviolin(cv_kNN.minmax, 'Min-Max'),
    plotoneviolin(cv_kNN.med, 'Median Scaling'),
    nrow=2,ncol=2
)

ggarrange(
    plotoneviolin(cv_kNN.mad, 'MAD Scaling'),
    plotoneviolin(cv_kNN.lm, 'Linear Regression'),
    plotoneviolin(cv_kNN.vsn, 'VSN'),
    plotoneviolin(cv_kNN.eig, 'EigenMS'),
    nrow=2,ncol=2
)
```

### Ludovic

```{r CV5}
cv_ludovic.before <- data.frame(KO=apply(2^LFQ_KO_ludovic, 1, cv), WT=apply(2^LFQ_WT_ludovic,1,cv))
cv_ludovic.standard <- data.frame(KO=apply(2^LFQ_KO_ludovic.standard, 1, cv), WT=apply(2^LFQ_WT_ludovic.standard, 1, cv))
cv_ludovic.minmax <- data.frame(KO=apply(2^LFQ_KO_ludovic.minmax, 1, cv), WT= apply(2^LFQ_WT_ludovic.minmax, 1, cv))
cv_ludovic.med <- data.frame(KO=apply(2^LFQ_KO_ludovic.med, 1, cv), WT=apply(2^LFQ_WT_ludovic.med, 1, cv))
cv_ludovic.mad <- data.frame(KO=apply(2^LFQ_KO_ludovic.mad, 1, cv), WT=apply(2^LFQ_WT_ludovic.mad, 1, cv))
cv_ludovic.lm <- data.frame(KO=apply(2^LFQ_KO_ludovic.lm, 1, cv), WT=apply(2^LFQ_WT_ludovic.lm, 1, cv))
cv_ludovic.vsn <- data.frame(KO=apply(2^LFQ_KO_ludovic.vsn, 1, cv), WT=apply(2^LFQ_WT_ludovic.vsn, 1, cv))
cv_ludovic.eig <- data.frame(KO=apply(2^LFQ_KO_ludovic.eigen, 1, cv), WT=apply(2^LFQ_WT_ludovic.eigen, 1, cv))

ggarrange(
    plotoneviolin(cv_ludovic.before, 'Original'),
    plotoneviolin(cv_ludovic.standard, 'Z-Score'),
    plotoneviolin(cv_ludovic.minmax, 'Min-Max'),
    plotoneviolin(cv_ludovic.med, 'Median Scaling'),
    nrow=2,ncol=2
)

ggarrange(
    plotoneviolin(cv_ludovic.mad, 'MAD Scaling'),
    plotoneviolin(cv_ludovic.lm, 'Linear Regression'),
    plotoneviolin(cv_ludovic.vsn, 'VSN'),
    plotoneviolin(cv_ludovic.eig, 'EigenMS'),
    nrow=2,ncol=2
)
```

### Summary

```{r}
cv_all <- data.frame(cv.before, cv.standard, cv.minmax, cv.med,
                     cv.mad, cv.lm, cv.vsn)
colnames(cv_all) <- c('Before_KO', 'Before_WT', 'Z-score_KO', 'Z-score_WT',
                          'MinMax_KO', 'MinMax_WT', 'Median_KO', 'Median_WT', 
                          'MAD_KO', 'MAD_WT', 'Linear_KO', 'Linear_WT', 
                          'VSN_KO', 'VSN_WT')
colnames(cv.eig) <- c('EigenMS_KO', 'EigenMS_WT')

cv_imp_all <- data.frame(cv_imp.before, cv_imp.standard, cv_imp.minmax, cv_imp.med,
                         cv_imp.mad, cv_imp.lm, cv_imp.vsn, cv_imp.eig)
colnames(cv_imp_all) <- c('Before_KO', 'Before_WT', 'Z-score_KO', 'Z-score_WT',
                          'MinMax_KO', 'MinMax_WT', 'Median_KO', 'Median_WT', 
                          'MAD_KO', 'MAD_WT', 'Linear_KO', 'Linear_WT', 
                          'VSN_KO', 'VSN_WT', 'EigenMS_KO', 'EigenMS_WT')

cv_RF_all <- data.frame(cv_RF.before, cv_RF.standard, cv_RF.minmax, cv_RF.med,
                         cv_RF.mad, cv_RF.lm, cv_RF.vsn, cv_RF.eig)
colnames(cv_RF_all) <- c('Before_KO', 'Before_WT', 'Z-score_KO', 'Z-score_WT',
                          'MinMax_KO', 'MinMax_WT', 'Median_KO', 'Median_WT', 
                          'MAD_KO', 'MAD_WT', 'Linear_KO', 'Linear_WT', 
                          'VSN_KO', 'VSN_WT', 'EigenMS_KO', 'EigenMS_WT')

cv_kNN_all <- data.frame(cv_kNN.before, cv_kNN.standard, cv_kNN.minmax, cv_kNN.med,
                         cv_kNN.mad, cv_kNN.lm, cv_kNN.vsn, cv_kNN.eig)
colnames(cv_kNN_all) <- c('Before_KO', 'Before_WT', 'Z-score_KO', 'Z-score_WT',
                          'MinMax_KO', 'MinMax_WT', 'Median_KO', 'Median_WT', 
                          'MAD_KO', 'MAD_WT', 'Linear_KO', 'Linear_WT', 
                          'VSN_KO', 'VSN_WT', 'EigenMS_KO', 'EigenMS_WT')

cv_ludovic_all <- data.frame(cv_ludovic.before, cv_ludovic.standard, cv_ludovic.minmax, cv_ludovic.med,
                         cv_ludovic.mad, cv_ludovic.lm, cv_ludovic.vsn, cv_ludovic.eig)
colnames(cv_ludovic_all) <- c('Before_KO', 'Before_WT', 'Z-score_KO', 'Z-score_WT',
                          'MinMax_KO', 'MinMax_WT', 'Median_KO', 'Median_WT', 
                          'MAD_KO', 'MAD_WT', 'Linear_KO', 'Linear_WT', 
                          'VSN_KO', 'VSN_WT', 'EigenMS_KO', 'EigenMS_WT')
```

```{r}
#### NON-IMPUTED ####
cv_summary_KO <- cv_all %>%
    select(contains('KO')) %>%
    pivot_longer(everything(), names_to = 'method KO', values_to = 'LFQ_CV') %>%
    group_by(`method KO`) %>%
    summarise('mean_KO'=round(mean(LFQ_CV, na.rm=TRUE),5), 
              'median_KO'=round(median(LFQ_CV, na.rm=TRUE),5), 
              'sd_KO'=round(sd(LFQ_CV, na.rm=TRUE),5))

cv_summary_eigen_KO <- tibble(cv.eig) %>%
    select(contains('KO')) %>%
    pivot_longer(everything(), names_to = 'method KO', values_to = 'LFQ_CV') %>%
    group_by(`method KO`) %>%
    summarise('mean_KO'=round(mean(LFQ_CV, na.rm=TRUE),5), 
              'median_KO'=round(median(LFQ_CV, na.rm=TRUE),5), 
              'sd_KO'=round(sd(LFQ_CV, na.rm=TRUE),5))

cv_summary_WT <- cv_all %>%
    select(contains('WT')) %>%
    pivot_longer(everything(), names_to = 'method WT', values_to = 'LFQ_CV') %>%
    group_by(`method WT`) %>%
    summarise('mean_WT'=round(mean(LFQ_CV, na.rm=TRUE),5), 
              'median_WT'=round(median(LFQ_CV, na.rm=TRUE),5), 
              'sd_WT'=round(sd(LFQ_CV, na.rm=TRUE),5))

cv_summary_eigen_WT <- tibble(cv.eig) %>%
    select(contains('WT')) %>%
    pivot_longer(everything(), names_to = 'method WT', values_to = 'LFQ_CV') %>%
    group_by(`method WT`) %>%
    summarise('mean_WT'=round(mean(LFQ_CV, na.rm=TRUE),5), 
              'median_WT'=round(median(LFQ_CV, na.rm=TRUE),5), 
              'sd_WT'=round(sd(LFQ_CV, na.rm=TRUE),5))

#### MATI CODE ####
cv_imp_summary_KO <- cv_imp_all %>%
    select(contains('KO')) %>%
    pivot_longer(everything(), names_to = 'method KO', values_to = 'LFQ_CV') %>%
    group_by(`method KO`) %>%
    summarise('mean_KO'=round(mean(LFQ_CV, na.rm=TRUE),5), 
              'median_KO'=round(median(LFQ_CV, na.rm=TRUE),5), 
              'sd_KO'=round(sd(LFQ_CV, na.rm=TRUE),5))

cv_imp_summary_WT <- cv_imp_all %>%
    select(contains('WT')) %>%
    pivot_longer(everything(), names_to = 'method WT', values_to = 'LFQ_CV') %>%
    group_by(`method WT`) %>%
    summarise('mean_WT'=round(mean(LFQ_CV, na.rm=TRUE),5), 
              'median_WT'=round(median(LFQ_CV, na.rm=TRUE),5), 
              'sd_WT'=round(sd(LFQ_CV, na.rm=TRUE),5))

#### RANDOM FOREST ####
cv_RF_summary_KO <- cv_RF_all %>%
    select(contains('KO')) %>%
    pivot_longer(everything(), names_to = 'method KO', values_to = 'LFQ_CV') %>%
    group_by(`method KO`) %>%
    summarise('mean_KO'=round(mean(LFQ_CV, na.rm=TRUE),5), 
              'median_KO'=round(median(LFQ_CV, na.rm=TRUE),5), 
              'sd_KO'=round(sd(LFQ_CV, na.rm=TRUE),5))

cv_RF_summary_WT <- cv_RF_all %>%
    select(contains('WT')) %>%
    pivot_longer(everything(), names_to = 'method WT', values_to = 'LFQ_CV') %>%
    group_by(`method WT`) %>%
    summarise('mean_WT'=round(mean(LFQ_CV, na.rm=TRUE),5), 
              'median_WT'=round(median(LFQ_CV, na.rm=TRUE),5), 
              'sd_WT'=round(sd(LFQ_CV, na.rm=TRUE),5))

#### K-NEAREST NEIGHBORS ####
cv_kNN_summary_KO <- cv_kNN_all %>%
    select(contains('KO')) %>%
    pivot_longer(everything(), names_to = 'method KO', values_to = 'LFQ_CV') %>%
    group_by(`method KO`) %>%
    summarise('mean_KO'=round(mean(LFQ_CV, na.rm=TRUE),5), 
              'median_KO'=round(median(LFQ_CV, na.rm=TRUE),5), 
              'sd_KO'=round(sd(LFQ_CV, na.rm=TRUE),5))

cv_kNN_summary_WT <- cv_kNN_all %>%
    select(contains('WT')) %>%
    pivot_longer(everything(), names_to = 'method WT', values_to = 'LFQ_CV') %>%
    group_by(`method WT`) %>%
    summarise('mean_WT'=round(mean(LFQ_CV, na.rm=TRUE),5), 
              'median_WT'=round(median(LFQ_CV, na.rm=TRUE),5), 
              'sd_WT'=round(sd(LFQ_CV, na.rm=TRUE),5))

#### LUDOVIC ####
cv_ludovic_summary_KO <- cv_ludovic_all %>%
    select(contains('KO')) %>%
    pivot_longer(everything(), names_to = 'method KO', values_to = 'LFQ_CV') %>%
    group_by(`method KO`) %>%
    summarise('mean_KO'=round(mean(LFQ_CV, na.rm=TRUE),5), 
              'median_KO'=round(median(LFQ_CV, na.rm=TRUE),5), 
              'sd_KO'=round(sd(LFQ_CV, na.rm=TRUE),5))

cv_ludovic_summary_WT <- cv_ludovic_all %>%
    select(contains('WT')) %>%
    pivot_longer(everything(), names_to = 'method WT', values_to = 'LFQ_CV') %>%
    group_by(`method WT`) %>%
    summarise('mean_WT'=round(mean(LFQ_CV, na.rm=TRUE),5), 
              'median_WT'=round(median(LFQ_CV, na.rm=TRUE),5), 
              'sd_WT'=round(sd(LFQ_CV, na.rm=TRUE),5))

#### SUMMARY ####
cv_summary <- as.data.frame(cbind(rbind(cv_summary_KO, cv_summary_eigen_KO),
                                  rbind(cv_summary_WT[-1], cv_summary_eigen_WT[-1])))
colnames(cv_summary)[1] <- 'method'
cv_summary$method <- gsub('_KO', '', cv_summary$method)
cv_summary <- cv_summary |> arrange(method)

cv_imp_summary <- as.data.frame(cbind(cv_imp_summary_KO, cv_imp_summary_WT[-1]))
colnames(cv_imp_summary)[1] <- 'method'
cv_imp_summary$method <- gsub('_KO', '', cv_imp_summary$method)

cv_RF_summary <- as.data.frame(cbind(cv_RF_summary_KO, cv_RF_summary_WT[-1]))
colnames(cv_RF_summary)[1] <- 'method'
cv_RF_summary$method <- gsub('_KO', '', cv_RF_summary$method)

cv_kNN_summary <- as.data.frame(cbind(cv_kNN_summary_KO, cv_kNN_summary_WT[-1]))
colnames(cv_kNN_summary)[1] <- 'method'
cv_kNN_summary$method <- gsub('_KO', '', cv_kNN_summary$method)

cv_ludovic_summary <- as.data.frame(cbind(cv_ludovic_summary_KO, cv_ludovic_summary_WT[-1]))
colnames(cv_ludovic_summary)[1] <- 'method'
cv_ludovic_summary$method <- gsub('_KO', '', cv_ludovic_summary$method)
```

#### Non-Imputed 

```{r}
show_cv_table(cv_summary)
```

#### Imputed - Mati Code 

```{r}
show_cv_table(cv_imp_summary)
```

#### Random Forest 

```{r}
show_cv_table(cv_RF_summary)
```

#### K-Nearest Neighbors 

```{r}
show_cv_table(cv_kNN_summary)
```

#### Ludovic

```{r}
show_cv_table(cv_ludovic_summary)
```

## ICC {.tabset}

After normalization, biological replicates should group more tightly. You can 
assess this by measuring the intraclass correlation coefficient (ICC) to see if 
replicates cluster together.

A guidelines for interpretation by [Koo and Li (2016)](https://doi.org/10.1016%2Fj.jcm.2016.02.012):

* below 0.50: poor <span style="color:#D3D3D3;font-size:16px"></span>
* between 0.50 and 0.75: moderate <span style="color:#aefda1;font-size:16px"></span>
* between 0.75 and 0.90: good <span style="color:#6dff54;font-size:16px"></span>
* above 0.90: excellent <span style="color:#1bb400;font-size:16px"></span>

### Non-Imputed

```{r ICC1}
icc.KO.before <- irr::icc(2^LFQ_KO)$value
icc.KO.standard <- irr::icc(2^LFQ_KO.standard)$value
icc.KO.minmax <- irr::icc(2^LFQ_KO.minmax)$value
icc.KO.med <- irr::icc(2^LFQ_KO.med)$value
icc.KO.mad <- irr::icc(2^LFQ_KO.mad)$value
icc.KO.lm <- irr::icc(2^LFQ_KO.lm)$value
icc.KO.vsn <- irr::icc(2^LFQ_KO.vsn)$value
icc.KO.eig <- irr::icc(2^LFQ_KO.eigen)$value

icc.KO.all <- data.frame(`ICC KO`=c(icc.KO.before, icc.KO.standard, icc.KO.minmax, icc.KO.med,
                                    icc.KO.mad, icc.KO.lm, icc.KO.vsn, icc.KO.eig))
rownames(icc.KO.all) <- c('Before', 'Z-score', 'MinMax', 'Median', 'MAD', 'Linear', 
                       'VSN', 'EigenMS')

icc.WT.before <- irr::icc(2^LFQ_WT)$value
icc.WT.standard <- irr::icc(2^LFQ_WT.standard)$value
icc.WT.minmax <- irr::icc(2^LFQ_WT.minmax)$value
icc.WT.med <- irr::icc(2^LFQ_WT.med)$value
icc.WT.mad <- irr::icc(2^LFQ_WT.mad)$value
icc.WT.lm <- irr::icc(2^LFQ_WT.lm)$value
icc.WT.vsn <- irr::icc(2^LFQ_WT.vsn)$value
icc.WT.eig <- irr::icc(2^LFQ_WT.eigen)$value

icc.WT.all <- data.frame(`ICC WT`=c(icc.WT.before, icc.WT.standard, icc.WT.minmax, icc.WT.med,
                                    icc.WT.mad, icc.WT.lm, icc.WT.vsn, icc.WT.eig))
rownames(icc.WT.all) <- c('Before', 'Z-score', 'MinMax', 'Median', 'MAD', 'Linear', 
                       'VSN', 'EigenMS')

DT::datatable(cbind(icc.KO.all, icc.WT.all), 
              options=list(searching=FALSE, paging=FALSE, info=FALSE)) %>%
    DT::formatStyle(columns = 'ICC.KO', 
                    background = DT::styleInterval(c(0.5,0.75,0.9), c('#D3D3D3', '#aefda1', '#6dff54', '#1bb400'))) %>%
    DT::formatStyle(columns = 'ICC.WT', 
                    background = DT::styleInterval(c(0.5,0.75,0.9), c('#D3D3D3', '#aefda1', '#6dff54', '#1bb400')))
```

### Mati Code

```{r ICC2}
icc_imp.KO.before <- irr::icc(2^LFQ_KO_imp)$value
icc_imp.KO.standard <- irr::icc(2^LFQ_KO_imp.standard)$value
icc_imp.KO.minmax <- irr::icc(2^LFQ_KO_imp.minmax)$value
icc_imp.KO.med <- irr::icc(2^LFQ_KO_imp.med)$value
icc_imp.KO.mad <- irr::icc(2^LFQ_KO_imp.mad)$value
icc_imp.KO.lm <- irr::icc(2^LFQ_KO_imp.lm)$value
icc_imp.KO.vsn <- irr::icc(2^LFQ_KO_imp.vsn)$value
icc_imp.KO.eig <- irr::icc(2^LFQ_KO_imp.eigen)$value

icc_imp.KO.all <- data.frame(`ICC KO`=c(icc_imp.KO.before, icc_imp.KO.standard, 
                                        icc_imp.KO.minmax, icc_imp.KO.med, 
                                        icc_imp.KO.mad, icc_imp.KO.lm, 
                                        icc_imp.KO.vsn, icc_imp.KO.eig))
rownames(icc_imp.KO.all) <- c('Before', 'Z-score', 'MinMax', 'Median', 'MAD', 'Linear', 
                       'VSN', 'EigenMS')

icc_imp.WT.before <- irr::icc(2^LFQ_WT_imp)$value
icc_imp.WT.standard <- irr::icc(2^LFQ_WT_imp.standard)$value
icc_imp.WT.minmax <- irr::icc(2^LFQ_WT_imp.minmax)$value
icc_imp.WT.med <- irr::icc(2^LFQ_WT_imp.med)$value
icc_imp.WT.mad <- irr::icc(2^LFQ_WT_imp.mad)$value
icc_imp.WT.lm <- irr::icc(2^LFQ_WT_imp.lm)$value
icc_imp.WT.vsn <- irr::icc(2^LFQ_WT_imp.vsn)$value
icc_imp.WT.eig <- irr::icc(2^LFQ_WT_imp.eigen)$value

icc_imp.WT.all <- data.frame(`ICC WT`=c(icc_imp.WT.before, icc_imp.WT.standard, 
                                        icc_imp.WT.minmax, icc_imp.WT.med, 
                                        icc_imp.WT.mad, icc_imp.WT.lm, 
                                        icc_imp.WT.vsn, icc_imp.WT.eig))
rownames(icc_imp.WT.all) <- c('Before', 'Z-score', 'MinMax', 'Median', 'MAD', 'Linear', 
                       'VSN', 'EigenMS')

DT::datatable(cbind(icc_imp.KO.all, icc_imp.WT.all), 
              options=list(searching=FALSE, paging=FALSE, info=FALSE)) %>%
    DT::formatStyle(columns = 'ICC.KO', 
                    background = DT::styleInterval(c(0.5,0.75,0.9), c('#D3D3D3', '#aefda1', '#6dff54', '#1bb400'))) %>%
    DT::formatStyle(columns = 'ICC.WT', 
                    background = DT::styleInterval(c(0.5,0.75,0.9), c('#D3D3D3', '#aefda1', '#6dff54', '#1bb400')))
```

### Random Forest

```{r ICC3}
icc_RF.KO.before <- irr::icc(2^LFQ_KO_RF)$value
icc_RF.KO.standard <- irr::icc(2^LFQ_KO_RF.standard)$value
icc_RF.KO.minmax <- irr::icc(2^LFQ_KO_RF.minmax)$value
icc_RF.KO.med <- irr::icc(2^LFQ_KO_RF.med)$value
icc_RF.KO.mad <- irr::icc(2^LFQ_KO_RF.mad)$value
icc_RF.KO.lm <- irr::icc(2^LFQ_KO_RF.lm)$value
icc_RF.KO.vsn <- irr::icc(2^LFQ_KO_RF.vsn)$value
icc_RF.KO.eig <- irr::icc(2^LFQ_KO_RF.eigen)$value

icc_RF.KO.all <- data.frame(`ICC KO`=c(icc_RF.KO.before, icc_RF.KO.standard, 
                                       icc_RF.KO.minmax, icc_RF.KO.med, 
                                       icc_RF.KO.mad, icc_RF.KO.lm, 
                                       icc_RF.KO.vsn, icc_RF.KO.eig))
rownames(icc_RF.KO.all) <- c('Before', 'Z-score', 'MinMax', 'Median', 'MAD', 'Linear', 
                       'VSN', 'EigenMS')

icc_RF.WT.before <- irr::icc(2^LFQ_WT_RF)$value
icc_RF.WT.standard <- irr::icc(2^LFQ_WT_RF.standard)$value
icc_RF.WT.minmax <- irr::icc(2^LFQ_WT_RF.minmax)$value
icc_RF.WT.med <- irr::icc(2^LFQ_WT_RF.med)$value
icc_RF.WT.mad <- irr::icc(2^LFQ_WT_RF.mad)$value
icc_RF.WT.lm <- irr::icc(2^LFQ_WT_RF.lm)$value
icc_RF.WT.vsn <- irr::icc(2^LFQ_WT_RF.vsn)$value
icc_RF.WT.eig <- irr::icc(2^LFQ_WT_RF.eigen)$value

icc_RF.WT.all <- data.frame(`ICC WT`=c(icc_RF.WT.before, icc_RF.WT.standard, 
                                       icc_RF.WT.minmax, icc_RF.WT.med,
                                       icc_RF.WT.mad, icc_RF.WT.lm, 
                                       icc_RF.WT.vsn, icc_RF.WT.eig))
rownames(icc_RF.WT.all) <- c('Before', 'Z-score', 'MinMax', 'Median', 'MAD', 'Linear', 
                       'VSN', 'EigenMS')

DT::datatable(cbind(icc_RF.KO.all, icc_RF.WT.all), 
              options=list(searching=FALSE, paging=FALSE, info=FALSE)) %>%
    DT::formatStyle(columns = 'ICC.KO', 
                    background = DT::styleInterval(c(0.5,0.75,0.9), c('#D3D3D3', '#aefda1', '#6dff54', '#1bb400'))) %>%
    DT::formatStyle(columns = 'ICC.WT', 
                    background = DT::styleInterval(c(0.5,0.75,0.9), c('#D3D3D3', '#aefda1', '#6dff54', '#1bb400')))
```

### K-Nearest Neighbors

```{r ICC4}
icc_kNN.KO.before <- irr::icc(2^LFQ_KO_kNN)$value
icc_kNN.KO.standard <- irr::icc(2^LFQ_KO_kNN.standard)$value
icc_kNN.KO.minmax <- irr::icc(2^LFQ_KO_kNN.minmax)$value
icc_kNN.KO.med <- irr::icc(2^LFQ_KO_kNN.med)$value
icc_kNN.KO.mad <- irr::icc(2^LFQ_KO_kNN.mad)$value
icc_kNN.KO.lm <- irr::icc(2^LFQ_KO_kNN.lm)$value
icc_kNN.KO.vsn <- irr::icc(2^LFQ_KO_kNN.vsn)$value
icc_kNN.KO.eig <- irr::icc(2^LFQ_KO_kNN.eigen)$value

icc_kNN.KO.all <- data.frame(`ICC KO`=c(icc_kNN.KO.before, icc_kNN.KO.standard, 
                                        icc_kNN.KO.minmax, icc_kNN.KO.med,
                                        icc_kNN.KO.mad, icc_kNN.KO.lm, 
                                        icc_kNN.KO.vsn, icc_kNN.KO.eig))
rownames(icc_kNN.KO.all) <- c('Before', 'Z-score', 'MinMax', 'Median', 'MAD', 'Linear', 
                       'VSN', 'EigenMS')

icc_kNN.WT.before <- irr::icc(2^LFQ_WT_kNN)$value
icc_kNN.WT.standard <- irr::icc(2^LFQ_WT_kNN.standard)$value
icc_kNN.WT.minmax <- irr::icc(2^LFQ_WT_kNN.minmax)$value
icc_kNN.WT.med <- irr::icc(2^LFQ_WT_kNN.med)$value
icc_kNN.WT.mad <- irr::icc(2^LFQ_WT_kNN.mad)$value
icc_kNN.WT.lm <- irr::icc(2^LFQ_WT_kNN.lm)$value
icc_kNN.WT.vsn <- irr::icc(2^LFQ_WT_kNN.vsn)$value
icc_kNN.WT.eig <- irr::icc(2^LFQ_WT_kNN.eigen)$value

icc_kNN.WT.all <- data.frame(`ICC WT`=c(icc_kNN.WT.before, icc_kNN.WT.standard, 
                                        icc_kNN.WT.minmax, icc_kNN.WT.med, 
                                        icc_kNN.WT.mad, icc_kNN.WT.lm, 
                                        icc_kNN.WT.vsn, icc_kNN.WT.eig))
rownames(icc_kNN.WT.all) <- c('Before', 'Z-score', 'MinMax', 'Median', 'MAD', 'Linear', 
                       'VSN', 'EigenMS')

DT::datatable(cbind(icc_kNN.KO.all, icc_kNN.WT.all), 
              options=list(searching=FALSE, paging=FALSE, info=FALSE)) %>%
    DT::formatStyle(columns = 'ICC.KO', 
                    background = DT::styleInterval(c(0.5,0.75,0.9), c('#D3D3D3', '#aefda1', '#6dff54', '#1bb400'))) %>%
    DT::formatStyle(columns = 'ICC.WT', 
                    background = DT::styleInterval(c(0.5,0.75,0.9), c('#D3D3D3', '#aefda1', '#6dff54', '#1bb400')))
```

### Ludovic

```{r ICC5}
icc_ludovic.KO.before <- irr::icc(2^LFQ_KO_ludovic)$value
icc_ludovic.KO.standard <- irr::icc(2^LFQ_KO_ludovic.standard)$value
icc_ludovic.KO.minmax <- irr::icc(2^LFQ_KO_ludovic.minmax)$value
icc_ludovic.KO.med <- irr::icc(2^LFQ_KO_ludovic.med)$value
icc_ludovic.KO.mad <- irr::icc(2^LFQ_KO_ludovic.mad)$value
icc_ludovic.KO.lm <- irr::icc(2^LFQ_KO_ludovic.lm)$value
icc_ludovic.KO.vsn <- irr::icc(2^LFQ_KO_ludovic.vsn)$value
icc_ludovic.KO.eig <- irr::icc(2^LFQ_KO_ludovic.eigen)$value

icc_ludovic.KO.all <- data.frame(`ICC KO`=c(icc_ludovic.KO.before, icc_ludovic.KO.standard,
                                            icc_ludovic.KO.minmax, icc_ludovic.KO.med, 
                                            icc_ludovic.KO.mad, icc_ludovic.KO.lm, 
                                            icc_ludovic.KO.vsn, icc_ludovic.KO.eig))
rownames(icc_ludovic.KO.all) <- c('Before', 'Z-score', 'MinMax', 'Median', 'MAD', 'Linear', 
                       'VSN', 'EigenMS')

icc_ludovic.WT.before <- irr::icc(2^LFQ_WT_ludovic)$value
icc_ludovic.WT.standard <- irr::icc(2^LFQ_WT_ludovic.standard)$value
icc_ludovic.WT.minmax <- irr::icc(2^LFQ_WT_ludovic.minmax)$value
icc_ludovic.WT.med <- irr::icc(2^LFQ_WT_ludovic.med)$value
icc_ludovic.WT.mad <- irr::icc(2^LFQ_WT_ludovic.mad)$value
icc_ludovic.WT.lm <- irr::icc(2^LFQ_WT_ludovic.lm)$value
icc_ludovic.WT.vsn <- irr::icc(2^LFQ_WT_ludovic.vsn)$value
icc_ludovic.WT.eig <- irr::icc(2^LFQ_WT_ludovic.eigen)$value

icc_ludovic.WT.all <- data.frame(`ICC WT`=c(icc_ludovic.WT.before, icc_ludovic.WT.standard, 
                                            icc_ludovic.WT.minmax, icc_ludovic.WT.med, 
                                            icc_ludovic.WT.mad, icc_ludovic.WT.lm, 
                                            icc_ludovic.WT.vsn, icc_ludovic.WT.eig))
rownames(icc_ludovic.WT.all) <- c('Before', 'Z-score', 'MinMax', 'Median', 'MAD', 'Linear', 
                       'VSN', 'EigenMS')

DT::datatable(cbind(icc_ludovic.KO.all, icc_ludovic.WT.all), 
              options=list(searching=FALSE, paging=FALSE, info=FALSE)) %>%
    DT::formatStyle(columns = 'ICC.KO', 
                    background = DT::styleInterval(c(0.5,0.75,0.9), c('#D3D3D3', '#aefda1', '#6dff54', '#1bb400'))) %>%
    DT::formatStyle(columns = 'ICC.WT', 
                    background = DT::styleInterval(c(0.5,0.75,0.9), c('#D3D3D3', '#aefda1', '#6dff54', '#1bb400')))
```

## t-test {.tabset}

### Z-Score

**Summary** <br>
The p-value plots look very bad, which means that we have lost whole differences 
between the samples.

```{r p-value raw data standardization}
standard_df <- data.frame(LFQ_KO.standard, LFQ_WT.standard)
standard_df[is.na(standard_df)] <- 0

pvalue_standard <- standard_df |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(standard_df, 1, ttest, 
                  grp1=grep("KO", colnames(standard_df)), 
                  grp2=grep("WT", colnames(standard_df)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_standard <- ggplot(data = pvalue_standard, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Non-Imputed - p.value')
```

```{r p-value imputed data standardization}
standard_df_imp <- data.frame(LFQ_KO_imp.standard, LFQ_WT_imp.standard)

pvalue_standard_imp <- standard_df_imp |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(standard_df_imp, 1, ttest, 
                  grp1=grep("KO", colnames(standard_df_imp)), 
                  grp2=grep("WT", colnames(standard_df_imp)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_standard_imp <- ggplot(data = pvalue_standard_imp, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed Mati Code - p.value') + theme(legend.position = 'none')
```

```{r p-value rf data standardization}
standard_df_RF <- data.frame(LFQ_KO_RF.standard, LFQ_WT_RF.standard)

pvalue_standard_RF <- standard_df_RF |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(standard_df_RF, 1, ttest, 
                  grp1=grep("KO", colnames(standard_df_RF)), 
                  grp2=grep("WT", colnames(standard_df_RF)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_standard_RF <- ggplot(data = pvalue_standard_RF, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed RF - p.value') + theme(legend.position = 'none')
```

```{r p-value kNN data standardization}
standard_df_kNN <- data.frame(LFQ_KO_kNN.standard, LFQ_WT_kNN.standard)

pvalue_standard_kNN <- standard_df_kNN |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(standard_df_kNN, 1, ttest, 
                  grp1=grep("KO", colnames(standard_df_kNN)), 
                  grp2=grep("WT", colnames(standard_df_kNN)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_standard_kNN <- ggplot(data = pvalue_standard_kNN, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed kNN - p.value') + theme(legend.position = 'none')
```

```{r p-value ludovic data standardization}
standard_df_ludovic <- data.frame(LFQ_KO_ludovic.standard, LFQ_WT_ludovic.standard)

pvalue_standard_ludovic <- standard_df_ludovic |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(standard_df_ludovic, 1, ttest, 
                  grp1=grep("KO", colnames(standard_df_ludovic)), 
                  grp2=grep("WT", colnames(standard_df_ludovic)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_standard_ludovic <- ggplot(data = pvalue_standard_ludovic, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed ludovic - p.value') + theme(legend.position = 'none')
```

```{r fig.height=3, fig.width=5}
hist_p_standard
```

```{r}
ggarrange(
    hist_p_standard_imp,
    hist_p_standard_RF,
    hist_p_standard_kNN,
    hist_p_standard_ludovic,
    nrow=2,ncol=2
)
```

### Min-Max

**Summary** <br>
Again the p-value plots look very bad, which means that we have again lost whole 
differences between the samples.

```{r p-value raw data minmax}
minmax_df <- data.frame(LFQ_KO.minmax, LFQ_WT.minmax)
minmax_df[is.na(minmax_df)] <- 0

pvalue_minmax <- minmax_df |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(minmax_df, 1, ttest, 
                  grp1=grep("KO", colnames(minmax_df)), 
                  grp2=grep("WT", colnames(minmax_df)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_minmax <- ggplot(data = pvalue_minmax, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Non-Imputed - p.value')
```

```{r p-value imputed data minmax}
minmax_df_imp <- data.frame(LFQ_KO_imp.minmax, LFQ_WT_imp.minmax)

pvalue_minmax_imp <- minmax_df_imp |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(minmax_df_imp, 1, ttest, 
                  grp1=grep("KO", colnames(minmax_df_imp)), 
                  grp2=grep("WT", colnames(minmax_df_imp)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_minmax_imp <- ggplot(data = pvalue_minmax_imp, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed Mati Code - p.value') + theme(legend.position = 'none')
```

```{r p-value rf data minmax}
minmax_df_RF <- data.frame(LFQ_KO_RF.minmax, LFQ_WT_RF.minmax)

pvalue_minmax_RF <- minmax_df_RF |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(minmax_df_RF, 1, ttest, 
                  grp1=grep("KO", colnames(minmax_df_RF)), 
                  grp2=grep("WT", colnames(minmax_df_RF)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_minmax_RF <- ggplot(data = pvalue_minmax_RF, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed RF - p.value') + theme(legend.position = 'none')
```

```{r p-value kNN data minmax}
minmax_df_kNN <- data.frame(LFQ_KO_kNN.minmax, LFQ_WT_kNN.minmax)

pvalue_minmax_kNN <- minmax_df_kNN |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(minmax_df_kNN, 1, ttest, 
                  grp1=grep("KO", colnames(minmax_df_kNN)), 
                  grp2=grep("WT", colnames(minmax_df_kNN)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_minmax_kNN <- ggplot(data = pvalue_minmax_kNN, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed kNN - p.value') + theme(legend.position = 'none')
```

```{r p-value ludovic data minmax}
minmax_df_ludovic <- data.frame(LFQ_KO_ludovic.minmax, LFQ_WT_ludovic.minmax)

pvalue_minmax_ludovic <- minmax_df_ludovic |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(minmax_df_ludovic, 1, ttest, 
                  grp1=grep("KO", colnames(minmax_df_ludovic)), 
                  grp2=grep("WT", colnames(minmax_df_ludovic)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_minmax_ludovic <- ggplot(data = pvalue_minmax_ludovic, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed ludovic - p.value') + theme(legend.position = 'none')
```

```{r fig.height=3, fig.width=5}
hist_p_minmax
```

```{r}
ggarrange(
    hist_p_minmax_imp,
    hist_p_minmax_RF,
    hist_p_minmax_kNN,
    hist_p_minmax_ludovic,
    nrow=2,ncol=2
)
```

### Median Scaling

**Summary**<br>
Again the p-value plots look very bad, which means that we have again lost whole 
differences between the samples.

```{r p-value raw data median}
med_df <- data.frame(LFQ_KO.med, LFQ_WT.med)
med_df[is.na(med_df)] <- 0

pvalue_med <- med_df |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(med_df, 1, ttest, 
                  grp1=grep("KO", colnames(med_df)), 
                  grp2=grep("WT", colnames(med_df)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_med <- ggplot(data = pvalue_med, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Non-Imputed - p.value')
```

```{r p-value imputed data median}
med_df_imp <- data.frame(LFQ_KO_imp.med, LFQ_WT_imp.med)

pvalue_med_imp <- med_df_imp |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(med_df_imp, 1, ttest, 
                  grp1=grep("KO", colnames(med_df_imp)), 
                  grp2=grep("WT", colnames(med_df_imp)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_med_imp <- ggplot(data = pvalue_med_imp, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed Mati Code - p.value') + theme(legend.position = 'none')
```

```{r p-value rf data median}
med_df_RF <- data.frame(LFQ_KO_RF.med, LFQ_WT_RF.med)

pvalue_med_RF <- med_df_RF |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(med_df_RF, 1, ttest, 
                  grp1=grep("KO", colnames(med_df_RF)), 
                  grp2=grep("WT", colnames(med_df_RF)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_med_RF <- ggplot(data = pvalue_med_RF, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed RF - p.value') + theme(legend.position = 'none')
```

```{r p-value kNN data median}
med_df_kNN <- data.frame(LFQ_KO_kNN.med, LFQ_WT_kNN.med)

pvalue_med_kNN <- med_df_kNN |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(med_df_kNN, 1, ttest, 
                  grp1=grep("KO", colnames(med_df_kNN)), 
                  grp2=grep("WT", colnames(med_df_kNN)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_med_kNN <- ggplot(data = pvalue_med_kNN, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed kNN - p.value') + theme(legend.position = 'none')
```

```{r p-value ludovic data median}
med_df_ludovic <- data.frame(LFQ_KO_ludovic.med, LFQ_WT_ludovic.med)

pvalue_med_ludovic <- med_df_ludovic |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(med_df_ludovic, 1, ttest, 
                  grp1=grep("KO", colnames(med_df_ludovic)), 
                  grp2=grep("WT", colnames(med_df_ludovic)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_med_ludovic <- ggplot(data = pvalue_med_ludovic, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed ludovic - p.value') + theme(legend.position = 'none')
```

```{r fig.height=3, fig.width=5}
hist_p_med
```

```{r}
ggarrange(
    hist_p_med_imp,
    hist_p_med_RF,
    hist_p_med_kNN,
    hist_p_med_ludovic,
    nrow=2,ncol=2
)
```

### Mad Scaling

**Summary**<br>
Again the p-value plots look very bad, which means that we have again lost whole 
differences between the samples.

```{r p-value raw data mad}
mad_df <- data.frame(LFQ_KO.mad, LFQ_WT.mad)
mad_df[is.na(mad_df)] <- 0

pvalue_mad <- mad_df |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(mad_df, 1, ttest, 
                  grp1=grep("KO", colnames(mad_df)), 
                  grp2=grep("WT", colnames(mad_df)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_mad <- ggplot(data = pvalue_mad, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Non-Imputed - p.value')
```

```{r p-value imputed data mad}
mad_df_imp <- data.frame(LFQ_KO_imp.mad, LFQ_WT_imp.mad)

pvalue_mad_imp <- mad_df_imp |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(mad_df_imp, 1, ttest, 
                  grp1=grep("KO", colnames(mad_df_imp)), 
                  grp2=grep("WT", colnames(mad_df_imp)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_mad_imp <- ggplot(data = pvalue_mad_imp, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed Mati Code - p.value') + theme(legend.position = 'none')
```

```{r p-value rf data mad}
mad_df_RF <- data.frame(LFQ_KO_RF.mad, LFQ_WT_RF.mad)

pvalue_mad_RF <- mad_df_RF |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(mad_df_RF, 1, ttest, 
                  grp1=grep("KO", colnames(mad_df_RF)), 
                  grp2=grep("WT", colnames(mad_df_RF)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_mad_RF <- ggplot(data = pvalue_mad_RF, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed RF - p.value') + theme(legend.position = 'none')
```

```{r p-value kNN data mad}
mad_df_kNN <- data.frame(LFQ_KO_kNN.mad, LFQ_WT_kNN.mad)

pvalue_mad_kNN <- mad_df_kNN |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(mad_df_kNN, 1, ttest, 
                  grp1=grep("KO", colnames(mad_df_kNN)), 
                  grp2=grep("WT", colnames(mad_df_kNN)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_mad_kNN <- ggplot(data = pvalue_mad_kNN, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed kNN - p.value') + theme(legend.position = 'none')
```

```{r p-value ludovic data mad}
mad_df_ludovic <- data.frame(LFQ_KO_ludovic.mad, LFQ_WT_ludovic.mad)

pvalue_mad_ludovic <- mad_df_ludovic |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(mad_df_ludovic, 1, ttest, 
                  grp1=grep("KO", colnames(mad_df_ludovic)), 
                  grp2=grep("WT", colnames(mad_df_ludovic)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_mad_ludovic <- ggplot(data = pvalue_mad_ludovic, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed ludovic - p.value') + theme(legend.position = 'none')
```

```{r fig.height=3, fig.width=5}
hist_p_mad
```

```{r}
ggarrange(
    hist_p_mad_imp,
    hist_p_mad_RF,
    hist_p_mad_kNN,
    hist_p_mad_ludovic,
    nrow=2,ncol=2
)
```

### Linear Regression

**Summary**<br>
Again the p-value plots look very bad, which means that we have again lost whole 
differences between the samples.

```{r p-value raw data lm}
lm_df <- data.frame(LFQ_KO.lm, LFQ_WT.lm)
lm_df[is.na(lm_df)] <- 0

pvalue_lm <- lm_df |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(lm_df, 1, ttest, 
                  grp1=grep("KO", colnames(lm_df)), 
                  grp2=grep("WT", colnames(lm_df)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_lm <- ggplot(data = pvalue_lm, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Non-Imputed - p.value')
```

```{r p-value imputed data lm}
lm_df_imp <- data.frame(LFQ_KO_imp.lm, LFQ_WT_imp.lm)

pvalue_lm_imp <- lm_df_imp |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(lm_df_imp, 1, ttest, 
                  grp1=grep("KO", colnames(lm_df_imp)), 
                  grp2=grep("WT", colnames(lm_df_imp)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_lm_imp <- ggplot(data = pvalue_lm_imp, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed Mati Code - p.value') + theme(legend.position = 'none')
```

```{r p-value rf data lm}
lm_df_RF <- data.frame(LFQ_KO_RF.lm, LFQ_WT_RF.lm)

pvalue_lm_RF <- lm_df_RF |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(lm_df_RF, 1, ttest, 
                  grp1=grep("KO", colnames(lm_df_RF)), 
                  grp2=grep("WT", colnames(lm_df_RF)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_lm_RF <- ggplot(data = pvalue_lm_RF, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed RF - p.value') + theme(legend.position = 'none')
```

```{r p-value kNN data lm}
lm_df_kNN <- data.frame(LFQ_KO_kNN.lm, LFQ_WT_kNN.lm)

pvalue_lm_kNN <- lm_df_kNN |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(lm_df_kNN, 1, ttest, 
                  grp1=grep("KO", colnames(lm_df_kNN)), 
                  grp2=grep("WT", colnames(lm_df_kNN)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_lm_kNN <- ggplot(data = pvalue_lm_kNN, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed kNN - p.value') + theme(legend.position = 'none')
```

```{r p-value ludovic data lm}
lm_df_ludovic <- data.frame(LFQ_KO_ludovic.lm, LFQ_WT_ludovic.lm)

pvalue_lm_ludovic <- lm_df_ludovic |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(lm_df_ludovic, 1, ttest, 
                  grp1=grep("KO", colnames(lm_df_ludovic)), 
                  grp2=grep("WT", colnames(lm_df_ludovic)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_lm_ludovic <- ggplot(data = pvalue_lm_ludovic, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed ludovic - p.value') + theme(legend.position = 'none')
```

```{r fig.height=3, fig.width=5}
hist_p_lm
```

```{r}
ggarrange(
    hist_p_lm_imp,
    hist_p_lm_RF,
    hist_p_lm_kNN,
    hist_p_lm_ludovic,
    nrow=2,ncol=2
)
```

### VNS

**Summary**<br>
Again the p-value plots look very bad, which means that we have again lost whole 
differences between the samples.

```{r p-value raw data vsn}
vsn_df <- data.frame(LFQ_KO.vsn, LFQ_WT.vsn)
vsn_df[is.na(vsn_df)] <- 0

pvalue_vsn <- vsn_df |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(vsn_df, 1, ttest, 
                  grp1=grep("KO", colnames(vsn_df)), 
                  grp2=grep("WT", colnames(vsn_df)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_vsn <- ggplot(data = pvalue_vsn, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Non-Imputed - p.value')
```

```{r p-value imputed data vsn}
vsn_df_imp <- data.frame(LFQ_KO_imp.vsn, LFQ_WT_imp.vsn)

pvalue_vsn_imp <- vsn_df_imp |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(vsn_df_imp, 1, ttest, 
                  grp1=grep("KO", colnames(vsn_df_imp)), 
                  grp2=grep("WT", colnames(vsn_df_imp)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_vsn_imp <- ggplot(data = pvalue_vsn_imp, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed Mati Code - p.value') + theme(legend.position = 'none')
```

```{r p-value rf data vsn}
vsn_df_RF <- data.frame(LFQ_KO_RF.vsn, LFQ_WT_RF.vsn)

pvalue_vsn_RF <- vsn_df_RF |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(vsn_df_RF, 1, ttest, 
                  grp1=grep("KO", colnames(vsn_df_RF)), 
                  grp2=grep("WT", colnames(vsn_df_RF)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_vsn_RF <- ggplot(data = pvalue_vsn_RF, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed RF - p.value') + theme(legend.position = 'none')
```

```{r p-value kNN data vsn}
vsn_df_kNN <- data.frame(LFQ_KO_kNN.vsn, LFQ_WT_kNN.vsn)

pvalue_vsn_kNN <- vsn_df_kNN |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(vsn_df_kNN, 1, ttest, 
                  grp1=grep("KO", colnames(vsn_df_kNN)), 
                  grp2=grep("WT", colnames(vsn_df_kNN)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_vsn_kNN <- ggplot(data = pvalue_vsn_kNN, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed kNN - p.value') + theme(legend.position = 'none')
```

```{r p-value ludovic data vsn}
vsn_df_ludovic <- data.frame(LFQ_KO_ludovic.vsn, LFQ_WT_ludovic.vsn)

pvalue_vsn_ludovic <- vsn_df_ludovic |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(vsn_df_ludovic, 1, ttest, 
                  grp1=grep("KO", colnames(vsn_df_ludovic)), 
                  grp2=grep("WT", colnames(vsn_df_ludovic)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_vsn_ludovic <- ggplot(data = pvalue_vsn_ludovic, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed ludovic - p.value') + theme(legend.position = 'none')
```

```{r fig.height=3, fig.width=5}
hist_p_vsn
```

```{r}
ggarrange(
    hist_p_vsn_imp,
    hist_p_vsn_RF,
    hist_p_vsn_kNN,
    hist_p_vsn_ludovic,
    nrow=2,ncol=2
)
```

### EigenMS

**Summary**<br>
Finally, we have the expected p-value plots, which means that the EigenMS method 
again has the best results.

```{r p-value raw data eigen}
eigen_df <- data.frame(LFQ_KO.eigen, LFQ_WT.eigen)
eigen_df[is.na(eigen_df)] <- 0

pvalue_eigen <- eigen_df |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(eigen_df, 1, ttest, 
                  grp1=grep("KO", colnames(eigen_df)), 
                  grp2=grep("WT", colnames(eigen_df)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_eigen <- ggplot(data = pvalue_eigen, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Non-Imputed - p.value')
```

```{r p-value imputed data eigen}
eigen_df_imp <- data.frame(LFQ_KO_imp.eigen, LFQ_WT_imp.eigen)

pvalue_eigen_imp <- eigen_df_imp |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(eigen_df_imp, 1, ttest, 
                  grp1=grep("KO", colnames(eigen_df_imp)), 
                  grp2=grep("WT", colnames(eigen_df_imp)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_eigen_imp <- ggplot(data = pvalue_eigen_imp, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed Mati Code - p.value') + theme(legend.position = 'none')
```

```{r p-value rf data eigen}
eigen_df_RF <- data.frame(LFQ_KO_RF.eigen, LFQ_WT_RF.eigen)

pvalue_eigen_RF <- eigen_df_RF |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(eigen_df_RF, 1, ttest, 
                  grp1=grep("KO", colnames(eigen_df_RF)), 
                  grp2=grep("WT", colnames(eigen_df_RF)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_eigen_RF <- ggplot(data = pvalue_eigen_RF, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed RF - p.value') + theme(legend.position = 'none')
```

```{r p-value kNN data eigen}
# The EigenMS function doesn't work well with kNN predicted data. In a few rows 
# we didn't have a unique value for each sample. Sometimes there was only one 
# value for all columns and sometimes there were two values, one for KO and the 
# other for WT. That's why we had to remove duplicates from data.

eigen_df_kNN <- data.frame(LFQ_KO_kNN.eigen, LFQ_WT_kNN.eigen)

# handling with duplicates
duplicates <- which(lapply(1:nrow(eigen_df_kNN), function(i) length(unique(as.numeric(eigen_df_kNN[i,])))) != 6)
eigen_df_kNN <- eigen_df_kNN[-duplicates,]

pvalue_eigen_kNN <- eigen_df_kNN |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(eigen_df_kNN, 1, ttest, 
                  grp1=grep("KO", colnames(eigen_df_kNN)), 
                  grp2=grep("WT", colnames(eigen_df_kNN)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_eigen_kNN <- ggplot(data = pvalue_eigen_kNN, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed kNN - p.value') + theme(legend.position = 'none')
```

```{r p-value ludovic data eigen}
eigen_df_ludovic <- data.frame(LFQ_KO_ludovic.eigen, LFQ_WT_ludovic.eigen)

pvalue_eigen_ludovic <- eigen_df_ludovic |>
    dplyr::mutate("p_OCIAD1_TOTALS" = apply(eigen_df_ludovic, 1, ttest, 
                  grp1=grep("KO", colnames(eigen_df_ludovic)), 
                  grp2=grep("WT", colnames(eigen_df_ludovic)))) |>
    dplyr::mutate(significant = ifelse(p_OCIAD1_TOTALS < p.cutoff, TRUE, FALSE))

hist_p_eigen_ludovic <- ggplot(data = pvalue_eigen_ludovic, aes(x = p_OCIAD1_TOTALS, fill=significant)) + 
    geom_histogram(bins = 100) + ggtitle('Imputed ludovic - p.value') + theme(legend.position = 'none')
```

```{r fig.height=3, fig.width=5}
hist_p_eigen
```

```{r}
ggarrange(
    hist_p_eigen_imp,
    hist_p_eigen_RF,
    hist_p_eigen_kNN,
    hist_p_eigen_ludovic,
    nrow=2,ncol=2
)
```













